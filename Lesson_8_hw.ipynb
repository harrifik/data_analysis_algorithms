{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIAqr2CPdfJe"
   },
   "source": [
    "# Урок 8. Снижение размерности данных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**План занятия**\n",
    "\n",
    "* [Теоретическая часть](#theory)\n",
    "    * [Алгоритмы снижения размерности](#reduce)\n",
    "        * [Отбор признаков](#selection)\n",
    "            * [Одномерный отбор признаков](#one_selection)\n",
    "            * [Переборные методы](#iterate)\n",
    "            * [Встроенные в модели](#integrated)\n",
    "        * [Понижение размерности ](#reduce_dims)\n",
    "            * [Метод главных компонент (PCA)](#pca)\n",
    "* [Домашнее задание](#hw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Теоретическая часть<a class=\"anchor\" id=\"theory\"></a><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOcLKigsdfJg"
   },
   "source": [
    "Большая размерность данных (под ней понимается размерность пространства признаков, то есть их количество) может серьезно усложнить задачу анализа таких данных и даже стать причиной некорректной работы некоторых алгоритмов. Кроме того, часто в исходных данных могут присутствовать лишние признаки, никак не связанные с целевой переменной. Поэтому часто встает задача понижения количества признаков, оставляя при этом самые значимые (наиболее сильно влияющие на значение целевого параметра) с отсечением менее значимых (наиболее слабо коррелирующих со значением целевого параметра) или с формированием новых признаков на основе старых. То есть ставится задача перехода от пространства большей размерности к пространству меньшей размерности с сохранением максимального количества полезной информации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Pa5-7u-dfJh"
   },
   "source": [
    "## Алгоритмы снижения размерности <a class='anchor' id='reduce'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zspAp10fdfJi"
   },
   "source": [
    "Алгоритмы снижения размерности пространства признаков делятся на две группы - **отбор признаков** (то есть отбрасывание наименее важных признаков) и **понижение размерности** путем формирования новых признаков на основе старых."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lmvx3YA5dfJj"
   },
   "source": [
    "## Отбор признаков <a class='anchor' id='selection'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Одномерный отбор признаков <a class='anchor' id='one_selection'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isLulqvJdfJk"
   },
   "source": [
    "Самым простым и примитивным методом отбора является _одномерный отбор признаков_. Он заключается в оценке предсказательной силы каждого признака, то есть его информативности - насколько он коррелирует с целевой переменной. Затем отбираются либо заданное количество $k$ признаков, либо те признаки, информативность которых выше некоторого порога."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U547aIwTdfJl"
   },
   "source": [
    "Оценка предсказательной силы признака (или степени связи этого признака и целевой переменной) может проводиться разными методами, например:\n",
    "\n",
    "- в случае регрессии - _корреляция_ $$R_{j} = \\frac{\\sum_{i=1}^{l}(x_{ij} - \\bar{x}_{j})(y_{i} - \\bar{y})}{\\sqrt{\\sum_{i=1}^{l}(x_{ij} - \\bar{x}_{j})^{2}\\sum_{i=1}^{l}(y_{i} - \\bar{y})^{2}}},$$ где $\\bar{x_{j}}$ и $\\bar{y}$ - среднее значение $j$-го признака и целевой переменной, соответственно. Чем больше по модулю корреляция ($\\pm 1$), тем информативнее признак. Следует заметить, что этот метод учитывает только линейную связь между признаком и целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.65970362,  0.39742884],\n",
       "       [ 1.53913966, -0.00891776],\n",
       "       [-0.8992934 , -1.96656869],\n",
       "       ...,\n",
       "       [-1.47970732, -0.8396605 ],\n",
       "       [ 1.27819546,  0.50111136],\n",
       "       [-1.11403185, -0.81958452]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.38997880e+01, -7.60664818e-01, -1.67743895e+02,  1.58318169e+01,\n",
       "        5.22640035e+01, -1.27843520e+01, -1.72575347e+02,  1.05195977e+01,\n",
       "       -1.42697867e+02, -5.78147468e+01,  5.41343397e+01, -1.20885907e+02,\n",
       "       -1.26233185e+02,  7.35265661e+01, -6.10298235e+01, -6.98925265e+00,\n",
       "       -7.94462575e+01, -1.27974905e+02, -1.25318269e+02, -1.38664259e+01,\n",
       "       -1.33549363e+02, -1.01513357e+02, -3.39548758e+01,  3.61540426e+01,\n",
       "       -1.81778363e+02,  8.15681299e+01,  6.68779581e+01, -1.66167272e+00,\n",
       "        1.84745041e+02, -1.25089770e+02, -1.78319379e+01,  3.60475828e+01,\n",
       "       -5.10405100e+01,  6.00815207e+01,  1.73041738e+01, -1.26026378e+02,\n",
       "       -8.04151476e+00,  8.52453688e+00,  3.70225300e+01, -6.22075809e+01,\n",
       "        8.82474207e+00, -1.80644852e+01, -1.24194545e+01,  2.10893155e+01,\n",
       "        1.06544988e+02,  2.73816831e+02,  7.47635374e+01,  6.74450686e+00,\n",
       "       -1.39046724e+02, -3.50397872e+01,  7.08104304e+01,  1.29814899e+02,\n",
       "        7.05798205e+01, -5.24915580e+01, -7.34817222e+01, -7.30660309e+01,\n",
       "       -7.80376577e+01,  1.04065554e+02,  9.02012535e+01,  8.85229227e+00,\n",
       "       -1.30382589e+01,  5.28705973e+01, -8.01207789e+01,  1.60360749e+01,\n",
       "       -2.00556794e+01, -1.18981607e+01,  1.29332271e+00, -5.04249740e+01,\n",
       "        3.43718834e+01, -3.24097643e+01, -1.12582318e+02,  1.40528308e+02,\n",
       "        5.93975954e+01,  7.88820138e+01,  9.45572286e-02,  4.51963754e+01,\n",
       "       -5.30805281e+01,  3.91036871e+01,  1.11366284e+02,  5.22862547e+00,\n",
       "       -6.91194451e+01, -7.92233255e+01, -1.64412491e+02,  1.11586371e+02,\n",
       "        1.60086104e+02, -5.73419371e+01,  2.11753641e+01,  3.20740947e+00,\n",
       "       -1.32184149e+01,  8.19362311e+01, -4.59786778e+01,  5.95112095e+01,\n",
       "       -4.87809550e+01, -7.48566433e+01,  7.68957596e+01,  1.66414663e+02,\n",
       "        1.40649673e+02, -4.83888974e+01,  1.22764702e+02, -1.37584247e+02,\n",
       "        1.49814254e+02,  2.46461569e+01,  4.76608031e+01,  6.94438725e+01,\n",
       "        7.32123974e+01,  1.18021902e+02,  4.21317172e+01, -5.19203041e+00,\n",
       "       -7.04070758e+00, -1.16456381e+02, -2.78192726e+01, -2.38756728e+01,\n",
       "        1.57739381e+01,  1.65280758e+02, -5.71961654e+00,  1.53369331e+02,\n",
       "       -3.84428191e+01,  4.36913482e+01, -8.89406558e+01, -3.67180024e+01,\n",
       "        1.39500894e+01,  8.15038731e+01,  8.49171894e+01,  1.08529071e+02,\n",
       "        5.34755600e+01, -1.52150757e+01, -5.44131660e+01,  5.70547609e+01,\n",
       "        3.24364405e+01, -1.23365935e+01,  7.96842277e+01,  1.63537142e+02,\n",
       "        3.98730531e+01,  2.13583473e+02,  2.45113342e+01, -4.26405713e+01,\n",
       "       -1.78399560e+00, -2.14099073e+01,  4.53135836e+01, -1.08007368e+02,\n",
       "       -6.02467727e+01,  1.21606956e+02, -6.61956094e+01, -8.32529960e+01,\n",
       "       -9.06741137e+01, -5.39575718e+01, -1.93679274e+01,  2.52401432e+01,\n",
       "        4.92101643e+01,  2.36640685e+01, -6.14415137e+01,  9.41159510e+01,\n",
       "        3.37041446e+01, -5.72374202e+01, -2.65558176e+01, -7.90297350e+01,\n",
       "       -6.59365293e+01, -9.80282410e+01,  2.03707655e+00, -3.46387687e+01,\n",
       "        4.79263602e+01, -8.33249916e+00, -1.41810493e+02, -1.95511176e+02,\n",
       "        4.09343172e+01,  1.92867607e+02,  8.69863071e+01,  6.66421464e+01,\n",
       "       -3.42696322e+01, -2.67450823e+01, -5.27895851e+01,  4.58087416e+01,\n",
       "        4.40449876e+01, -4.85328802e+01, -1.46626099e+01, -7.10274310e+00,\n",
       "       -4.71462305e+01,  7.23827519e+01, -8.27259714e+01, -1.61124593e+02,\n",
       "        1.02926790e+02, -4.77115897e+01, -9.92339074e+00, -4.55608916e+01,\n",
       "        9.96625643e+01,  1.41578828e+02, -1.30175597e+02, -4.47843382e+00,\n",
       "        1.91476056e+01, -1.50681880e+01,  1.84922872e+01,  2.56000836e+01,\n",
       "        5.08103383e+01, -1.24640004e+02, -1.50800369e+01, -1.02610888e+02,\n",
       "        6.19358885e+01, -4.18315452e+01,  4.01673981e+01, -8.68717497e+01,\n",
       "       -8.76204790e+01, -1.57769158e+01,  2.57675085e+01,  1.03253697e+02,\n",
       "       -6.51789989e+01, -1.65567965e+02,  9.22247331e+00, -9.39941310e+01,\n",
       "       -1.67405239e+01,  1.29816057e+02, -8.76580375e+01, -4.30999724e+01,\n",
       "       -8.58414780e+01,  3.09310576e+01,  1.37877370e+01,  7.23585526e+01,\n",
       "       -1.89038275e+02,  3.79453700e+01,  4.36752840e+01,  1.04697571e+02,\n",
       "       -1.40127836e+01,  9.08659154e+01, -1.34949526e+02, -1.13072703e+02,\n",
       "       -4.76584500e+01, -9.94089337e+01, -1.10981734e+02,  7.51553244e+01,\n",
       "        2.38616438e+00, -5.02767935e+00,  1.25290304e+02, -1.52530094e+01,\n",
       "       -4.10001756e+01, -2.40296861e+01,  1.20037618e+02,  7.44480791e+01,\n",
       "        9.64499566e+01, -5.65947286e+01, -1.26004224e+02, -1.12329647e+02,\n",
       "        6.71150187e+00, -1.72527230e+00,  3.70335860e+01, -2.52086251e+01,\n",
       "       -6.88242422e+01, -1.21888601e+02,  6.66799983e+01, -1.38137656e+01,\n",
       "       -5.02311263e+01,  3.42883653e+01, -1.06144927e+02, -1.03158223e+02,\n",
       "       -5.93840820e+01,  1.76892495e+01, -1.23366578e+02,  2.90632088e+01,\n",
       "        1.87064063e+01, -1.93894044e+01,  1.06730640e+02,  1.99988638e+02,\n",
       "        1.06475598e+02,  4.78756722e+01,  5.04281779e+01,  4.73768154e+01,\n",
       "       -2.81384975e+01, -2.56840052e+01, -1.34980654e+02,  3.16634153e+01,\n",
       "       -6.74566224e+01,  5.34791202e+00,  3.79781123e+01, -1.43540092e+01,\n",
       "       -9.10166111e+01, -9.08766582e+01,  1.75140776e+02, -2.36484147e+02,\n",
       "       -4.70452946e+01,  1.06592705e+02, -2.81030409e+01,  3.89710588e+01,\n",
       "       -1.14125098e+02, -3.06529126e+02,  9.44583021e+01, -1.11052622e+01,\n",
       "       -2.27924985e+02,  6.93025349e+01, -1.44784213e+01,  4.72897297e+01,\n",
       "        8.01092923e+01,  2.75964494e+01,  1.02196029e+01, -3.08980256e+01,\n",
       "       -5.55294697e+01, -8.67103651e+01, -3.26788001e+01,  8.45278084e+01,\n",
       "        9.27262391e+01,  2.29379448e+02, -5.54932326e+01, -9.08178300e+01,\n",
       "       -7.29488291e+01,  1.11453733e+02,  4.07217319e+01, -4.06028256e+01,\n",
       "       -7.12577312e+01,  3.61124176e+01, -9.49318554e+01, -7.28130567e+01,\n",
       "        1.64765467e-01,  7.60410220e+01,  2.89986673e+00, -3.71516418e+01,\n",
       "       -1.50028151e+02,  1.67602099e+02, -8.09183701e+01,  2.60092436e+02,\n",
       "        6.17691724e+01,  1.27546097e+02, -6.68357927e+01,  7.86750677e+00,\n",
       "       -9.02804928e+01,  1.04936073e+02, -1.35820644e+01, -1.03770259e+01,\n",
       "        4.76736369e+01,  2.01645153e+01, -2.43322224e+01,  2.98276414e+01,\n",
       "        5.75563697e+01,  8.80574972e+01, -1.20202081e+02, -2.21520409e+01,\n",
       "        2.25069789e+01,  7.54138676e+01, -1.02204087e+02, -4.24974542e+01,\n",
       "       -1.00124312e+02, -1.38473518e+02,  2.85034022e+00, -5.87043004e+01,\n",
       "        1.42549676e+01,  4.08244189e+00, -1.03180533e+02,  3.56521962e+01,\n",
       "       -1.93879754e+00,  8.35324066e-01,  5.44023023e+01,  6.90646821e+01,\n",
       "        4.89905005e+01, -8.40156243e+01, -7.73868082e+01, -7.22273297e+01,\n",
       "       -9.34470713e+01, -3.63779690e+01,  5.19705404e+01,  1.08418497e+02,\n",
       "       -9.63878467e+01, -3.63366580e+01, -9.32293877e+01,  2.79013510e+01,\n",
       "       -5.36056282e+01, -8.80776042e+01,  4.44914214e+00, -4.45259075e+01,\n",
       "       -5.59939313e+01,  8.61948763e+01,  1.33009755e+02, -7.02872493e+01,\n",
       "        4.12480402e+01,  8.70395651e+01,  8.38086301e+01, -2.83059942e+01,\n",
       "        8.04726278e+01,  1.05652596e+01,  3.07248129e+01,  1.27566200e+02,\n",
       "        4.28973918e+01,  1.86335475e+02,  1.28112138e+02,  5.42400818e+01,\n",
       "       -1.66371834e+02,  1.21333884e+02, -8.43495176e+00,  1.28155195e+02,\n",
       "       -7.22774203e+01, -1.36734551e+02,  9.57917500e+01,  6.06449254e+01,\n",
       "        3.37432113e+01, -4.45852064e+01, -7.58911381e+01,  2.00921662e+01,\n",
       "       -6.81240424e+01,  2.72168857e+02,  8.39094411e+01, -6.01518992e+01,\n",
       "        2.02874316e+01,  9.88807937e+01, -3.22733836e+01,  1.12015630e+02,\n",
       "        3.29098459e+01,  5.43155305e+00, -6.50084038e+01,  1.23277279e+02,\n",
       "        2.16135386e+01, -2.01050366e+02,  8.72624601e+01, -6.06216764e+01,\n",
       "        5.14515002e+01, -1.54004617e+02,  2.13846200e+00, -8.83690183e+01,\n",
       "        2.92262203e+01,  8.86406372e+01,  1.20617835e+01, -6.00776714e+01,\n",
       "       -1.29424944e+02, -1.38425567e+01,  2.45248227e+01,  6.01187779e+01,\n",
       "       -2.48100844e+02, -1.26746742e+02, -2.25660981e+02,  5.64460124e+01,\n",
       "        2.53063272e+01,  1.20133317e+02,  2.92526734e+01,  5.30309842e+00,\n",
       "       -5.05228576e+01, -6.64541205e+01,  6.77109935e+01, -1.22899519e+01,\n",
       "       -1.38415176e+02, -1.39076581e+01,  6.00697491e+01,  2.49846507e+01,\n",
       "       -1.85193495e+02,  1.73722568e+02,  1.14631229e+02,  6.22716588e+01,\n",
       "       -6.29065025e+01,  5.58101333e+01,  2.27435095e+01,  8.14213702e+01,\n",
       "       -1.18646885e+02, -8.91871800e+00, -1.18907967e+02, -2.04471526e+02,\n",
       "       -1.07625269e+02, -6.54551909e+01,  2.78999214e+01,  1.98597432e+00,\n",
       "       -1.14678964e+02, -2.26527992e+02, -2.30031120e+00,  3.28803137e+01,\n",
       "        1.14542666e+02,  9.17593311e+01,  1.39034111e+01,  1.83625805e+02,\n",
       "       -7.04454889e+00, -4.14591787e+01,  1.52899992e+01, -2.80950828e+01,\n",
       "       -4.04752664e+01,  2.70531987e+01, -8.69622973e+01,  6.42002750e+01,\n",
       "       -4.49062645e+01, -1.42656385e+02, -2.14733410e+02,  1.61902309e+02,\n",
       "       -4.54305273e+01,  3.53891856e+01, -7.81534035e+01, -9.41517383e+01,\n",
       "       -1.31984540e+01,  6.21938188e+01, -8.01910710e+01, -3.19809574e+01,\n",
       "        8.46214998e+01,  5.43625382e+01,  9.94689549e+01, -8.52843204e+00,\n",
       "        2.44959139e+01, -1.53999236e+02,  3.11550183e+01,  1.74261263e+02,\n",
       "        4.60298791e+01,  1.01194807e+02, -3.67424551e+01,  1.04780238e+02,\n",
       "       -9.51979504e+01,  8.30935447e+01, -1.11963131e+02, -2.05295131e+01,\n",
       "        9.64258077e+01,  2.47446688e+00, -6.65698411e+01,  3.04920226e+01,\n",
       "        1.49656094e+02,  1.92333068e+01,  7.53622925e+01, -1.02156938e+02,\n",
       "       -8.18170928e+01,  1.65595247e+02,  1.88274316e+01, -4.15485399e-01,\n",
       "        1.07955867e+02,  8.76752394e+01, -1.03727179e+02,  1.44463513e+02,\n",
       "       -1.54290034e+02,  8.44772622e+00,  4.27263151e+01, -3.20560093e+01,\n",
       "        3.15243727e+00,  3.28293066e+01,  1.95593122e+02,  1.89055697e+02,\n",
       "        2.71418478e+01, -2.56716265e+01,  2.07727471e+02,  9.62716759e+01,\n",
       "        1.69151133e+02,  1.91435645e+02, -8.93793295e+01,  2.18300797e+01,\n",
       "        9.11355945e+01, -3.82347054e+01, -2.18352016e+02,  7.72796501e+00,\n",
       "        1.19068032e+02,  2.46455413e+01, -1.61000659e+02, -7.81236699e+01,\n",
       "       -1.77509797e+01, -1.01790248e+02, -7.05707829e+01, -4.56033813e+01,\n",
       "       -4.34028586e+01, -2.11659045e+01, -1.86722975e+01, -2.02124346e+02,\n",
       "        4.81008896e+01,  2.74304469e+01,  6.54185622e+01, -2.54063615e+01,\n",
       "       -2.60069106e+01, -3.52249987e+01, -5.03135559e+01, -2.98562630e+00,\n",
       "       -1.24948684e+02,  1.62832396e+01, -4.67243271e+01,  1.35862539e+02,\n",
       "       -7.61782740e+01,  2.88842200e+01,  1.79589960e+01, -4.15744905e+01,\n",
       "        1.60359394e+02, -3.20049115e+01,  6.45579237e+00,  1.31591374e+02,\n",
       "       -8.93949776e+00, -6.21136458e+01,  1.55430338e+02, -1.80725663e+01,\n",
       "       -7.78030412e+01,  8.07929436e+01, -8.52422873e+01, -3.16009264e+01,\n",
       "        1.07563490e+01,  7.83225143e+01,  8.32099192e+00,  1.24899191e+02,\n",
       "        5.99503785e+01,  6.99287258e+01, -1.03281827e+02,  4.10579415e+01,\n",
       "       -1.27047436e+02, -6.24749638e+01, -5.68094176e+01,  6.95987698e+01,\n",
       "        4.43488841e+01,  3.00651951e+01,  5.75787705e+01, -2.32523439e+01,\n",
       "       -1.66736530e+02, -2.59779936e+01, -4.03394809e+01, -1.54066006e+02,\n",
       "       -5.88609587e+01,  9.14185555e+01, -4.87267242e+01,  9.41366738e+01,\n",
       "       -5.02415735e+01,  9.63216052e+01,  5.75991148e+01, -6.53411666e+01,\n",
       "        5.66253466e+01,  1.36152894e+02,  1.86233515e+02, -1.27079853e+02,\n",
       "        2.80484283e+01, -1.27919093e+01, -1.16964556e+01, -4.82741321e+01,\n",
       "       -9.26678959e+01, -6.29824716e+01,  2.33086641e+01,  6.03238812e+01,\n",
       "       -1.16525262e+02, -9.13122969e+01, -1.09369247e+02, -4.65063106e+01,\n",
       "       -5.86116785e+01, -1.16693946e+02,  6.61032506e+01,  6.41733115e+01,\n",
       "       -6.69450770e+01,  5.85679033e+01, -6.69069855e+01, -5.59712429e+01,\n",
       "        9.04109598e+00, -4.93051774e+01,  1.36700749e+02, -4.53816796e+00,\n",
       "       -2.41691335e+00, -6.47037780e+01, -1.85359284e+02, -2.72573851e+01,\n",
       "        2.98353679e+01,  8.86944593e+01, -7.14600414e+01, -3.92663615e+01,\n",
       "        4.67362459e+01,  7.52956702e+00,  3.62468003e+01,  1.23947651e+02,\n",
       "        7.38933975e+01, -9.67705647e+01,  1.33071429e+02, -2.13337668e+02,\n",
       "        4.54411891e+01, -6.94887148e+00, -2.22758251e+02,  1.55482093e+02,\n",
       "        6.66691411e+01,  1.73524793e+01,  5.75173780e+01,  6.19116083e+01,\n",
       "        1.27907205e+02,  1.28131625e+01, -4.86668236e+01,  7.43115263e+01,\n",
       "        3.07931456e+01, -1.30960989e+01,  2.87949828e+01, -7.78067891e+01,\n",
       "       -7.74855926e+01,  6.56236949e+01, -1.51415755e+01, -4.61425119e+00,\n",
       "       -5.95041313e+01, -7.22202034e+00, -2.45669685e+02,  1.45551777e+02,\n",
       "       -1.05940453e+01,  1.69609746e+00,  1.04255033e+02, -5.74704865e+01,\n",
       "       -1.68793456e+02,  1.19200233e+02, -4.77930712e+01, -3.48815045e+01,\n",
       "        5.23697388e+01,  1.08795025e+02, -1.17052786e+02,  5.87988735e+01,\n",
       "       -2.38498437e+01, -3.38564070e+01,  7.27093065e+01, -1.73675522e+02,\n",
       "        7.83157840e+01,  1.32585899e+01, -1.67449621e+02,  9.90988889e+01,\n",
       "       -4.05943462e+01, -2.40259527e+01,  5.48783714e+00,  1.79715437e+02,\n",
       "        5.97885278e+01,  4.16596622e+01,  1.23820918e+02,  7.12475825e+01,\n",
       "        4.46035600e+01, -3.83517149e+01,  1.14140778e+02,  1.03562573e+02,\n",
       "        1.20175834e+02,  1.21139760e+01,  4.98637475e+01,  2.91396205e+01,\n",
       "        4.80653427e+01, -2.69518698e+01, -2.95425231e+01,  1.16061772e+02,\n",
       "       -3.62164646e+01,  1.16686656e+02,  1.11212104e+02,  1.01878764e+02,\n",
       "       -7.54596535e+00, -4.02979493e+01, -5.98718331e+01,  6.93036073e+00,\n",
       "       -5.80851665e+01,  8.32679297e+00,  7.98117692e+01,  1.45325094e+02,\n",
       "        9.34613356e+01, -1.29882958e+02, -1.70826685e+01, -1.07868114e+01,\n",
       "        1.51507251e+01, -1.11266552e+02,  4.70602529e+01, -1.01019367e+01,\n",
       "        4.19008174e+01, -1.03218457e+01,  9.50241795e+01,  1.02606606e+02,\n",
       "       -2.61716835e+01, -5.24773183e+01, -4.93565787e+01, -2.70074414e+01,\n",
       "        1.72051579e+02,  7.31142977e+01, -4.77408751e+01, -1.29733974e+01,\n",
       "        2.38153261e+02,  1.45996173e+01,  1.96556778e+02, -8.07044004e+01,\n",
       "       -7.57422318e+01, -1.17853927e+00,  1.36484625e+02,  6.18516099e+01,\n",
       "       -1.19317753e+02, -1.61888874e+02, -1.49741774e+00,  7.63851737e+00,\n",
       "        3.66797902e+01, -3.89982134e+01,  1.01738401e+01,  5.20890391e+01,\n",
       "        1.05680643e+02, -9.30238116e+01,  4.61043647e+01,  5.10879757e+01,\n",
       "        1.28206996e+02,  7.89518222e+01,  8.48892938e+01,  1.16071595e+02,\n",
       "       -5.35615737e+01, -1.46116611e+00, -1.87395413e+00, -1.48789571e+02,\n",
       "        1.38450379e+02, -1.92622541e+02,  7.08142890e+01,  5.51078156e+01,\n",
       "       -1.74664954e+02, -3.37337483e+01, -1.01072849e+02,  1.92207992e+01,\n",
       "       -7.64605109e+01, -6.86645586e+01, -1.06227389e+02, -3.97332615e+01,\n",
       "       -9.84005699e+01, -6.61590210e+01, -1.18888219e+02,  3.36433084e+01,\n",
       "        1.03854899e+02, -5.08804454e+00,  1.22608908e+01,  3.11574732e+01,\n",
       "        6.48794165e+01, -1.05333240e+01,  4.84374792e+00,  2.87867981e+01,\n",
       "        2.57026608e+01,  2.08289097e+01,  3.14978828e+00,  8.29789347e+01,\n",
       "        3.41427945e+01,  8.32474460e+01,  4.28638940e+01, -6.28926276e+01,\n",
       "       -7.51721531e+00, -1.06234038e+01, -5.10159006e+01,  4.26849130e+01,\n",
       "        1.05499504e+02,  1.71504481e+01, -6.05724433e+00, -9.91271885e+01,\n",
       "       -1.70922992e+01, -1.71414336e+01,  4.22737108e+01,  2.24726114e+02,\n",
       "       -2.20964077e+00,  3.14246973e+00,  7.18770088e+01,  1.90259189e+02,\n",
       "       -7.65079187e+01, -2.09342235e+02,  5.07495480e+01, -6.65938141e+01,\n",
       "       -7.12245633e+01,  1.93688128e+01,  5.26404249e+01,  7.37473239e+00,\n",
       "       -1.57439975e+02, -5.65726199e+00,  8.39636485e+01,  1.04705538e+02,\n",
       "        7.84804277e+01,  1.24403157e+02,  3.02803055e+00,  1.55284406e+02,\n",
       "       -1.79963441e+02,  5.84745646e+01, -1.04132820e+02, -2.20100357e+01,\n",
       "        1.35161142e+02,  6.19399035e+01, -1.12035701e+02, -2.45763163e+01,\n",
       "       -2.04293838e+01, -2.26850507e+01, -4.32654434e+01,  6.79756135e+01,\n",
       "       -1.93558060e+01, -5.34862974e+01,  5.91342285e+01,  1.05526868e+00,\n",
       "       -8.26289988e+01,  2.07913502e+01,  4.57067130e+01, -3.72739317e+00,\n",
       "       -5.33213519e+01, -7.47140550e+01, -1.58763135e-01,  8.22442311e+01,\n",
       "        4.83227950e+01,  5.27104972e+01, -3.18467801e+01, -8.39737514e+01,\n",
       "        2.64012298e+00, -1.92603755e+02, -1.69815855e+02,  7.10017498e+01,\n",
       "       -9.57527054e+01, -1.02928548e+02, -7.49773896e+01, -8.63178398e+01,\n",
       "        6.29406440e+00, -1.82253213e+00,  4.87489890e+01, -1.61962704e+01,\n",
       "        6.09168964e+01, -3.39502026e+01,  2.97083127e+01, -7.09117751e+01,\n",
       "        3.08417080e+01,  9.25788340e+01, -6.67949375e+01,  9.89611378e+01,\n",
       "       -9.99309598e+01, -8.06664783e+01,  1.35109623e+01,  1.16170745e+02,\n",
       "       -5.97716299e+01,  1.12057031e+02,  1.84430527e+01,  1.93285360e+01,\n",
       "        8.54959204e+01, -5.18364343e+01,  1.24810660e+02,  2.70888893e+01,\n",
       "       -3.13854656e+01,  4.92739705e+01,  7.08705625e+01, -1.23780920e+02,\n",
       "       -1.70433139e+01,  8.41456521e+01,  6.19167755e+01,  8.44231867e+01,\n",
       "       -8.78258189e+01,  4.30559327e+00, -3.84630828e+01,  1.02653284e+01,\n",
       "       -1.19911144e+01, -7.82750146e+01, -7.68588450e+01, -7.41216548e+01,\n",
       "       -1.60827407e+01,  9.18211302e+01, -2.20122766e+01, -5.41214940e+01,\n",
       "       -4.15685482e+01,  8.59517490e+01,  1.28317231e+02, -5.74918713e+01,\n",
       "        8.00720868e+01,  1.16221845e+02, -6.71924472e+01,  3.18928207e+01,\n",
       "       -5.82271021e+01, -4.25876905e+01, -1.14172607e+02, -2.38268208e+02,\n",
       "       -2.11486230e+01,  8.28122812e+01, -5.41062829e+01, -1.51857385e+01,\n",
       "        1.79477590e+01,  4.60853580e+01,  1.83320264e+02,  4.47140624e+00,\n",
       "        8.04473063e+01, -1.20726988e+02,  3.14422977e+01,  5.72139005e+01,\n",
       "       -2.55854156e+00, -1.01308012e+02, -2.31386571e+00,  1.00876199e+02,\n",
       "        1.01247137e+02, -4.48940074e+01,  1.78082096e+01,  1.13079945e+01,\n",
       "       -2.70662242e+01, -7.43147349e+01,  5.48820707e+01,  3.73590089e+01,\n",
       "        4.62620330e+01,  3.53966614e+01,  8.41818089e+01, -8.81970557e+01,\n",
       "        4.07500302e+01,  8.41154487e+01,  2.96930447e+01,  6.98973338e+01,\n",
       "       -6.70946501e+00,  4.06760603e+00,  7.07698316e+00,  6.79775570e+01,\n",
       "       -6.13043487e+01,  6.72416974e+01,  1.43773951e+02,  5.23381656e+01,\n",
       "        1.77498899e+01, -2.89435876e+00, -2.99700125e+01, -8.62026234e+01,\n",
       "        1.35551071e+02, -1.77808246e+02,  1.34037150e+02,  1.42224468e+02,\n",
       "        8.55929995e+01,  8.43487492e+01, -1.07545838e+02,  5.43525578e+01,\n",
       "       -7.29434705e+01, -1.11380362e+02, -5.02519575e+01, -4.21154949e+01,\n",
       "        1.64015487e+02,  1.11945497e+02, -3.27382335e+01, -6.85641940e+01,\n",
       "        3.13855727e+01, -1.03763461e+02,  9.32471495e+01,  8.34718673e+01,\n",
       "       -5.44822144e+01, -3.95853073e+01,  6.58782300e+01, -7.16074959e+01,\n",
       "       -2.57365449e+01, -7.69398712e+01, -2.44196087e+01, -2.05403742e+01,\n",
       "        9.81074718e-01, -7.16211561e+01,  4.27436746e+01, -6.99087203e+01])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "np.random.seed(9)\n",
    "X_rgr, y_rgr = make_regression(n_samples=1000, n_features=2, n_informative=1, n_targets=1)\n",
    "\n",
    "display(X_rgr, y_rgr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R_{j} = \\frac{\\sum_{i=1}^{l}(x_{ij} - \\bar{x}_{j})(y_{i} - \\bar{y})}{\\sqrt{\\sum_{i=1}^{l}(x_{ij} - \\bar{x}_{j})^{2}\\sum_{i=1}^{l}(y_{i} - \\bar{y})^{2}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция 0 признака с целевой переменной 0.024507486889396298\n",
      "Корреляция 1 признака с целевой переменной 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "def corr(x, y):\n",
    "    mean_x = x.mean()\n",
    "    mean_y = y.mean()\n",
    "    corr = np.sum((x - mean_x) * (y - mean_y)) / np.sqrt(np.sum((x - mean_x)**2) * np.sum((y - mean_y) ** 2))\n",
    "    return corr\n",
    "\n",
    "\n",
    "print(f'Корреляция 0 признака с целевой переменной {corr(X_rgr[:, 0], y_rgr)}')\n",
    "print(f'Корреляция 1 признака с целевой переменной {corr(X_rgr[:, 1], y_rgr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция 0 признака с целевой переменной 0.0245074868893963\n",
      "Корреляция 1 признака с целевой переменной 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Корреляция 0 признака с целевой переменной {np.corrcoef(X_rgr[:, 0], y_rgr)[0][1]}')\n",
    "print(f'Корреляция 1 признака с целевой переменной {np.corrcoef(X_rgr[:, 1], y_rgr)[0][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- в случае задачи классификации - *взаимная информация (mutual information)*, моделирующая корреляцию между признаками и классами. **Желательно, чтобы признак был тоже дискретным.** Она использует в расчете вероятность того, что одновременно значение $j$-го признака $x_{ij}$ равно числу $v$ и значение целевой переменной $y_{i}=k$, или, другими словами, долю таких объектов от общего количества объектов в выборке $P(x=v,y=k)$. Тогда взаимная информация будет находиться как $$MI_{j}=\\sum_{v \\in X}\\sum_{k \\in Y}P(x=v,y=k)\\text{log}\\frac{P(x=v,y=k)}{P(x=v)P(y=k)}.$$ Здесь $P(x=v)$ и $P(y=k)$ - доли объектов, на которых значение признака равно $v$ и значение целевой переменной равно $k$, соответственно. Если признак и целевая переменная независимы, то взаимная информация обращается в ноль. В отличие от предыдущего метода, этот метод позволяет находять произвольные зависимости (в т.ч. нелинейные) в пространстве произвольной размерности.\n",
    "\n",
    "$$P(x=v,y=k) = \\frac{1}{n}\\sum_{i=0}^n{[x_{ij}= v][y_i = k]}$$\n",
    "$$P(x=v) = \\frac{1}{n}\\sum_{i=0}^n{[x_{ij}= v]}$$\n",
    "$$P(y=k) = \\frac{1}{n}\\sum_{i=0}^n{[y_{j} = k]}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43599538, -1.55715109],\n",
       "       [ 1.43377716, -0.53632698],\n",
       "       [ 0.47503278, -1.31969664],\n",
       "       ...,\n",
       "       [ 0.89375686, -0.8061292 ],\n",
       "       [ 0.06075411,  0.59480138],\n",
       "       [-0.39229455,  2.05593842]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "np.random.seed(9)\n",
    "X_cls, y_cls = make_classification(n_samples=1000, n_features=2, n_informative=1, n_clusters_per_class=1,\n",
    "                                   n_redundant=1, n_classes=2)\n",
    "X_cls[:, 1] = np.random.randn(X_cls.shape[0])\n",
    "display(X_cls, y_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(X_cls[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cls[:, 0] = pd.cut(X_cls[:, 0], 10, labels=False)\n",
    "X_cls[:, 1] = pd.cut(X_cls[:, 1], 10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 13,  67, 149, 159,  86,  24,   3,   0,   0,   0],\n",
       "       [  0,   0,   2,   9,  65, 115, 143, 112,  41,  12]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contingency_matrix(y_cls, X_cls[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1                                                           \n",
       "0        0.0   1.0    2.0    3.0   4.0    5.0    6.0    7.0   8.0   9.0\n",
       "target                                                                 \n",
       "0       13.0  67.0  149.0  159.0  86.0   24.0    3.0    NaN   NaN   NaN\n",
       "1        NaN   NaN    2.0    9.0  65.0  115.0  143.0  112.0  41.0  12.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_cls)\n",
    "df['target'] = y_cls\n",
    "pd.pivot_table(df, index='target', columns=0, aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    159\n",
       "2.0    149\n",
       "4.0     86\n",
       "1.0     67\n",
       "5.0     24\n",
       "0.0     13\n",
       "6.0      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(X_cls[:, 0][y_cls == 0]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$MI_{j}=\\sum_{v \\in X}\\sum_{k \\in Y}P(x=v,y=k)\\text{log}\\frac{P(x=v,y=k)}{P(x=v)P(y=k)}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mi(x, y):\n",
    "    mi = 0\n",
    "    cm = contingency_matrix(y, x)\n",
    "    \n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            size = np.sum(cm)\n",
    "            p_x_y = cm[i][j] / size\n",
    "            p_x = np.sum(cm[:, j]) / size\n",
    "            p_y = np.sum(cm[i]) / size\n",
    "\n",
    "            if p_x_y == 0:\n",
    "                continue\n",
    "            mi += p_x_y * np.log(p_x_y / (p_x * p_y))\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Взаимная информация 0 признака с целевой переменной 0.4656395068265237\n",
      "Взаимная информация 1 признака с целевой переменной 0.0024864832627259493\n"
     ]
    }
   ],
   "source": [
    "print(f'Взаимная информация 0 признака с целевой переменной {get_mi(X_cls[:, 0], y_cls)}')\n",
    "print(f'Взаимная информация 1 признака с целевой переменной {get_mi(X_cls[:, 1], y_cls)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Взаимная информация 0 признака с целевой переменной 0.4656395068265234\n",
      "Взаимная информация 1 признака с целевой переменной 0.0024864832627257364\n"
     ]
    }
   ],
   "source": [
    "print(f'Взаимная информация 0 признака с целевой переменной {mutual_info_score(X_cls[:, 0], y_cls)}')\n",
    "print(f'Взаимная информация 1 признака с целевой переменной {mutual_info_score(X_cls[:, 1], y_cls)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такие методы позволяют оценить важность исключительно каждого признака отдельно, без учета влияния комбинаций признаков на целевую переменную, поэтому они и называются одномерными. На практике зачастую признаки влияют именно в совокупности, и по отдельности могут ошибочно быть расценены как некоррелирующие с целевой переменной, поэтому одномерные методы отбора не являются оптимальным методом в большинстве случаев.\n",
    "\n",
    "У одномерного отбора признаков есть проблема - они не учитывают взаимосвязь признаков, зависимость целевой переменной от сложной комбинации признаков.\n",
    "<img src='images/problem_1dim.png' width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переборные методы <a class='anchor' id='iterate'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DV5E5PnadfJl"
   },
   "source": [
    "Отдельной группой методов можно назвать так называемые *переборные методы*, которые дискретно оценивают качество модели, обученной на различных подмножествах признаков. При этом происходит полный перебор всех возможных вариантов. Обычно такие алгоритмы делятся на _жадные (greedy)_ и *нежадные (non-greedy)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOjQFkTgdfJm"
   },
   "source": [
    "Жадность алгоритмов заключаются в том, что если один из признаков включен в подмножество (или исключен в случае исключающего метода), в следующих итерациях поиска он уже не учитывается, так что алгоритм работает на меньшем объеме данных. Известные алгоритмы этого типа - _жадное включение_ и _жадное исключение_. В случае жадного включения на первой итерации аналогично одномерному отбору признаков находится признак, обладающий наибольшей предсказательной силой и добавляется в формирующуееся подмножество $\\{i_{1}\\}$. Далее происходит перебор оставшихся признаков с попеременным добавлением каждого из них в подмножество к первому и оценкой качества получаемой модели, обученной на подмножестве из этих двух признаков $\\{i_{1}, i_{2}\\}$. В итоге в подмножестве остается тот признак, при добавлении которого получается наилучшее качество. Далее эта процедура повторяется до момента, пока ошибка получаемой модели уменьшается. На каждой итерации в подмножество добавляется один признак, максимально улучшающий работу модели. Если на какой-то итерации при добавлении признаков ошибка не уменьшается, процесс останавливается.\n",
    "\n",
    "Плюсом такого алгоритма является относительная быстрота и возможность учета некоторых взаимодействий между признаками (как раз то, чего лишен одномерный отбор). Минусом же можно назвать вероятность застрять в локальном минимуме ошибки, если такой есть. В случае же когда есть единственный глобальный минимум, алгоритм найдет оптимальное решение. Добавив признак однажды, мы уже не сможем его убрать из обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример жадного алгоритма:**\n",
    "\n",
    "Есть 3 признака ($x_1, x_2, x_3$)<br>\n",
    "Будем обучать алгоритм:\n",
    "1. Находим лучший признак: обучаемся на $x_1$; $x_2$; $x_3$. Получаем $x_1$\n",
    "2. Находим признак, который сильнее всего уменьшает ошибку: обучаемся на $x_2$; $x_3$. Получаем $x_2$\n",
    "3. Снова ищем признак, который сильнее всего уменьшает ошибку: обучаемся на $x_3$. Получаем $x_3$\n",
    "\n",
    "Так далаем до тех пор, пока уменьшается ошибка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть также модификации этого алгоритма с многократным проходом по выборке и поочередным включением/исключением признаков из подмножества для учета совокупного влияния признаков. Он менее жадный и может исправлять ошибки перебора, которые могли допустить ранее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример менее жадного алгоритма (ADD-DEL):**\n",
    "\n",
    "1. Добавляем признаки, пока уменьшается ошибка (пример жадного алгоритма выше)\n",
    "2. Удаляем признаки, пока уменьшается ошибка\n",
    "3. Повторяем пунткы 1 и 2, пока уменьшается ошибка "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5TOTIM4dfJo"
   },
   "source": [
    "Примером нежадного алгоритма может быть простой последовательный полный перебор всех возможных подмножеств признаков. Такой подбор позволяет найти наиболее оптимальное подмножество признаков, но, очевидно, он является достаточно трудоемким, поэтому подходит только для датасетов с небольшим количеством признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример нежадного алгоритма:**\n",
    "\n",
    "Есть 3 признака ($x_1, x_2, x_3$)<br>\n",
    "Будем обучать алгоритм на подмножестве:\n",
    "- мощностью 1: $x_1$; $x_2$; $x_3$\n",
    "- мощностью 2: $x_1$ $x_2$; $x_1$ $x_3$; $x_2$ $x_3$\n",
    "- мощностью 3: $x_1$ $x_2$ $x_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Встроенные в модели <a class='anchor' id='integrated'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqDrhuvidfJp"
   },
   "source": [
    "Еще одна группа методов отбора признаков - _встроенные в модели_. Они используют эвристики, заложенные в обучающие модели, для оценки важности признаков.\n",
    "\n",
    "- Например, в случае работы с линейными моделями мы имеем зависимость целевой переменной от взвешенной суммы признаков $$a(x) = \\sum_{i=1}^{n}w_{i}x^{i}.$$ Здесь, если признаки масштабированы, веса будут являться показателями информативности признаков: чем больше вес, тем больший вклад данный признак вносит в значение целевой переменной. На основе этого показателя можно проводить отбор признаков. Также, вспоминая уроки по линейным моделям, можно упомянуть, что использование $L_{1}$-регуляризации приводит к занулению весов наименее важных признаков, то есть к их отбрасыванию, при этом больший коэффициент регуляризации будет приводить к большему количеству зануленных весов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , 85.29775533])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_rgr, y_rgr)\n",
    "\n",
    "display(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , 84.33033233])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso = Lasso(alpha=1)\n",
    "\n",
    "lasso.fit(X_rgr, y_rgr)\n",
    "\n",
    "display(lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMFGIpqQdfJr"
   },
   "source": [
    "- В случае использования решающих деревьев и их композиций, где в каждой вершине происходит разбиение на два поддерева путем сравнивания значения одного признака с некоторым значением порога, важность признака можно оценивать по тому, насколько он уменьшает значение критерия информативности, по которому оценивается качество разбиения: $$Q(X_{m}, j, t) = H(X_{m}) - \\frac{|X_{l}|}{|X_{m}|}H(X_{l}) - \\frac{|X_{r}|}{|X_{m}|}H(X_{r}),$$ где $X_{m}$ - множество объектов, попавших в вершину на данном шаге, $X_{l}$ и $X_{r}$ - множества, попадающие в левое и правое поддерево, соответственно, после разбиения. $H(X)$ - критерий информативности. \n",
    "    \n",
    "    Чем сильнее падает критерий информативности при разбиении по данному признаку (то есть чем выше $Q$), тем этот признак важнее. Таким образом, важность $j$-го признака можно оценить путем вычисления суммы уменьшений критерия информативности по всем вершинам, в которых делалось разбиение по данному признаку. Чем больше эта сумма, тем важнее данный признак был при построении дерева. В случае композиций деревьев этот показатель суммируется по всем деревьям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'permutation_importance' from 'sklearn.inspection' (C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\sklearn\\inspection\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e9d393e1489f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minspection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpermutation_importance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'permutation_importance' from 'sklearn.inspection' (C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\sklearn\\inspection\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "tree.fit(X_rgr, y_rgr)\n",
    "\n",
    "display(tree.feature_importances_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "plot_tree(tree, ax=ax, filled=True, max_depth=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-7c6ee8d94c3b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-7c6ee8d94c3b>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    2 -\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1 - shuffle\n",
    "2 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'permutation_importance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ebbf1ca28685>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpermutation_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_rgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_rgr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'permutation_importance' is not defined"
     ]
    }
   ],
   "source": [
    "permutation_importance(tree, X_rgr, y_rgr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suyYET13dfJr"
   },
   "source": [
    "## Понижение размерности <a class='anchor' id='reduce_dims'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Для чего может быть полезно понижение размерности:**\n",
    "\n",
    "*1. Визуализация*\n",
    "\n",
    "Тяжело визуализировать многомерное простаранство\n",
    "<img src='images/6dims.png' width=300>\n",
    "*2. Сжатие с сохранением смысла*\n",
    "\n",
    "Все признаки важные, отбрасывать их нельзя, но можно их сжать\n",
    "<img src='images/pca_reduce.png' width=300>\n",
    "*3. Абстрактные признаки*\n",
    "\n",
    "Получить новые признаки на основе старых\n",
    "<img src='images/retail.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8w8aSllUdfJs"
   },
   "source": [
    "### Метод случайных проекций\n",
    "\n",
    "Кроме отбора признаков, который не всегда оптимален в плане сохранения максимума полезной информации, существуют еще методы понижения размерности путем формирования новых признаков на основе старых. Новых признаков при использовании такого метода должно быть меньше, чем исходных, при условии сохранения максимально возможного количества информации из исходных признаков. Например, объединение нескольких признаков в линейную комбинацию:\n",
    "\n",
    "$$z_{ij}=\\sum_{k=1}^{D}w_{jk}x_{ik},$$\n",
    "\n",
    "где $x_{ij}$ - исходные признаки, $z_{ij}$ - новые признаки, а $w_{jk}$ - вклад исходного k-го признака в новый j-й."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2iJ7XBhdfJt"
   },
   "source": [
    "Простейшим методов такого понижения размерности является метод *случайных проекций*, который заключается в преобразованиях, сохраняющих расстояния и снижающих размерности.\n",
    "\n",
    "Линейный подход $z_{ij}=\\sum_{k=1}^{n}w_{jk}x_{ik}$, выбор весов случайный $w_{jk}\\sim N(0, \\frac{1}{d})$.\n",
    "\n",
    "Можем спроецировать выборку в пространство меньшей размерности, при этом расстояния между объектами мало изменятся.\n",
    "\n",
    "Существование таких преобразований доказано для выборок, в которых объектов меньше, чем признаков. Веса при всех признаках в таком методе можно выбирать случайно. При этом не факт, что мы попадем в оптимальное преобразование, но практика показывает, что метод работает, если размерность нового пространства признаков\n",
    "\n",
    "$$d > \\frac{8\\text{ln}l}{\\varepsilon^{2}},$$\n",
    "\n",
    "где $l$ - количество объектов, $\\varepsilon$ - максимальное изменение расстояния между объектами (лемма о малом искажении или лемма Джонсона-Линденштраусса).\n",
    "\n",
    "Хорошо работает для текстов, где признаков очень много."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps = 1e-2\n",
    "\n",
    "dots = np.linspace(1000, 30000, 1000)\n",
    "fs = list(map(lambda l: 8 * np.log(l) / eps ** 2, dots))\n",
    "\n",
    "plt.xlabel('кол-во наблюдений')\n",
    "plt.ylabel('кол-во признаков')\n",
    "plt.xlim(1000, 30000)\n",
    "plt.plot(dots, fs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RKYQxgMdfJu"
   },
   "source": [
    "#### Метод главных компонент (PCA) <a class='anchor' id='pca'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7frA6OrdfJv"
   },
   "source": [
    "Одним из наиболее известных и широко применяемых методов понижения размерности является _метод главных компонент (principal component analysis, PCA)_.\n",
    "<img src=\"images/pca_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем показанную ранее формулу линейного преобразования признаков в матричном виде:\n",
    "\n",
    "$$Z = XW^{T},$$\n",
    "\n",
    "где $X$ - матрица \"объекты-признаки\", где по строкам отложены объекты, а по столбцам - значения признаков, $Z$ - матрица новых признаков, $W^{T}$ - транспонированная матрица весов.\n",
    "\n",
    "При этом метод главных компонент предполагает, что матрица весов должна быть ортогональной, то есть произведение $WW^{T}$ должно равняться единичной матрице. \n",
    "\n",
    "Приближение заключается формировании новой матрицы признаков $\\tilde{X}=ZW\\approx X$ с возможностью восстанавливания старых признаков по новым с максимальным уровнем точности, или, если говорить иначе, чтобы их различие было минимальным:\n",
    "\n",
    "$$\\|ZW - X\\|^{2} \\rightarrow \\underset{Z, W}{\\text{min}}.$$\n",
    "\n",
    "$\\|X\\| = \\sqrt{\\sum_{i, j}x_{ij}^2}$ (Норма Фробениуса)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oGhpkBfdfJv"
   },
   "source": [
    " Восстановленная матрица $ZW$ может иметь ранг меньший, чем исходная $X$, поэтому приближение будет называться низкоранговым."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути это задача матричного разложения: мы хотим представить матрицу X в виде произведения ZW, которые будут иметь меньший ранг. То есть хотим уменьшить ранг, потеряв как можно меньше информации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-0bcbd767ed66>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-21-0bcbd767ed66>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    10 features\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "10 features\n",
    "5 informative\n",
    "5 redundant\n",
    "\n",
    "rank = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dV8i8cDdfJx"
   },
   "source": [
    "Если ранг матрицы исходных признаков $rank(X) \\geq d$, где $d$ - число новых признаков, то минимум функционала различия, описанного выше, достигается тогда, когда в качестве строк матрицы $W$ используются собственные векторы матрицы $X^{T}X$ , соответствующие максимальным собственным значениям $\\lambda_{1},...,\\lambda_{d}$. Максимальные собственные значения и называются главными компонентами, от чего пошло название метода. Первая главная компонента соответствует максимальному собственному значению и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P45TTDjedfJw"
   },
   "source": [
    "Геометрически метод можно представить как проецирование признаков на гиперплоскость с максимизацией дисперсии получаемой выборки.\n",
    "<img src='https://i.stack.imgur.com/Q7HIP.gif'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "kSmUQy4ZdfJ2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример \"на пальцах\"\n",
    "[Статья](https://habr.com/ru/post/304214/) про метод главных компонент\n",
    "\n",
    "В данной выборке у нас имеются два признака, сильно коррелирующие друг с другом. С помощью алгоритма PCA мы сможем найти новый признак и выразить оба этих признака одним новым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "x = np.arange(1, 11)\n",
    "y = 2 * x + np.random.randn(10) * 2\n",
    "\n",
    "X = np.vstack((x,y)).T\n",
    "plt.scatter(X[:, 0], X[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Для описания случайной величины используются мат. ожидание и дисперсия. Можно сказать, что мат. ожидание – это «центр тяжести» величины, а дисперсия – это ее «размеры». Грубо говоря, мат. ожидание задает положение случайной величины, а дисперсия – ее размер (точнее, разброс)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def standard_scale(x):\n",
    "    res = (x - x.mean(axis=0)) / x.std(axis=0)\n",
    "    return res\n",
    "\n",
    "\n",
    "X = standard_scale(X)\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае с многомерной случайной величиной (случайным вектором) положение центра все так же будет являться мат. ожиданиями ее проекций на оси. А вот для описания ее формы уже недостаточно только ее дисперсий по осям. \n",
    "\n",
    "Для описания формы случайного вектора необходима ковариационная матрица. Ковариационная матрица является обобщением дисперсии на случай многомерных случайных величин – она так же описывает форму (разброс) случайной величины, как и дисперсия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ковариация 0 признака (дисперсия 0 признака) 1.1111111111111112\n",
      "Ковариация 1 признака (дисперсия 1 признака) 1.111111111111111\n",
      "Ковариация 0 и 1 признака 1.055151566476865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.11111111, 1.05515157],\n",
       "       [1.05515157, 1.11111111]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вычислите массив a_centered, отняв от значений массива “а” средние значения\n",
    "# Найдите скалярное произведение столбцов массива a_centered. a_centered_sp на N-1, где N - число наблюдений.\n",
    "\n",
    "def covariance(x, y):\n",
    "    return np.sum(x * y) / (len(x) - 1)\n",
    "\n",
    "print(f'Ковариация 0 признака (дисперсия 0 признака) {covariance(X[:, 0], X[:, 0])}')\n",
    "print(f'Ковариация 1 признака (дисперсия 1 признака) {covariance(X[:, 1], X[:, 1])}')\n",
    "print(f'Ковариация 0 и 1 признака {covariance(X[:, 0], X[:, 1])}')\n",
    "cov = np.cov(X.T)\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.11111111, 1.05515157],\n",
       "       [1.05515157, 1.11111111]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T @ X / 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь надо найти такой вектор, при котором максимизировался бы размер (дисперсия) проекции нашей выборки на него."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3df3BU533v8fdXQhhhEQuDDEj8EI5BcfwrGIJtwFgiTXE8bXB8kxkndxKnTYbJvbXT3psysa+naab/2C3T3rmZpE3dJtNkmonDTR1CY3ppkrPih21iwGDLGOMQ79pIwmAbRJAtQEjf+4eOHCFWP/doz9ndz2tGo92zj87z4Ujoq/M8zzlr7o6IiEhZ3AFERCQZVBBERARQQRARkZAKgoiIACoIIiISUkEQEREggoJgZvPMLGVmh8zsoJn9aZY2ZmbfMLMjZvaCmd2ca78iIhKtSRHs4wLwFXd/zsymAfvM7Ofu/tKANh8DFoUftwD/EH4WEZGEyPkMwd2Puftz4eMzwCGgblCzdcD3vc9uoNrM5uTat4iIRCeKM4T3mFk9sAT41aCX6oCjA563htuOZdnHemA9wJQpU5bOnz8/yoiR6+3tpaws+VMxyhmtfOY80nmEqklVzJ4ye8xfq+MZrULI+corr7zl7jXj+mJ3j+QDqAL2Afdkee1JYNWA578Elo60z8WLF3vSpVKpuCOMinJGK18597Xvc76O/+vz/zqur9fxjFYh5AT2+jh/j0dS6sysAvg34Afu/kSWJq3AvAHP5wLtUfQtUsyCdABA08KmmJNIKYhilZEB3wEOufvfDdFsC/C5cLXRrcBpd79kuEhELhakAxpmNFA7rTbuKFICophDWAl8FmgxswPhtv8FzAdw928DW4G7gCPAu8AfRdCvSFHr7ulm5+s7+eyNn407ipSInAuCu+8CbIQ2DvxJrn2JlJK97XvpPN/JmoVr4o4iJSLZ0+UiJax//qCxvjHeIFIyVBBEEiqVSXHjrBuZOXVm3FGkRKggiCTQ2QtneeroU6yp13CR5I8KgkgC7W7dzdkLZ7XcVPJKBUEkgVLpFGVWxuoFq+OOIiUk0ltXiEg0gkzA0jlLqZ5SHXcUGcLm/W1s3HaY9o4uaqsr2bC2gbuXDL6NW2HRGYJIwrxz/h12t+7WctME27y/jYeeaKGtowsH2jq6eOiJFjbvb4s7Wk5UEEQSZtfru7jQe4Gmes0fJNXGbYfp6u65aFtXdw8btx2OKVE0VBBEEiaVSTGpbBKr5q+KO4oMob2ja0zbC4UKgkjCBOmAW+feyuWTL487igyhtrpyTNsLhQqCSIKcPnuafcf2abgo4TasbaCyovyibZUV5WxY2xBTomholZFIgux4bQe93qsJ5YTrX01UbKuMVBBEEiRIB0yZNIVb594adxQZwd1L6gq+AAymISORBAkyASvmrWDKpClxR5ESpIIgkhBvvfsWLxx/QfcvktioIIgkRHOmGUDzBxIbzSGIJESQDqiaXMWy2mVxRyk4xXgbiTioIIgkRCqT4vb5t1NRXhF3lILSfxuJ/iuH+28jAagojFEkQ0Zm9l0zO2FmLw7xeqOZnTazA+HH16LoV6RYtJ9p5+W3XtZw0TgU620k4hDVGcK/AN8Evj9Mm53u/gcR9SdSVFLpFKD5g/Eo1ttIxCGSMwR33wGcjGJfIqUoSAdUT6nmplk3xR2l4BTrbSTikM9VRreZ2fNm9h9mdl0e+xVJvFQmRWN9I+Vl5SM3losU620k4mDuHs2OzOqBn7n79Vleex/Q6+6dZnYX8H/cfdEQ+1kPrAeoqalZumnTpkjyTZTOzk6qqqrijjEi5YxWlDmPdR3jM89+hgeueYB76u6JZJ/9SuV4dnR1c/z0Wc739DK5vIxZV0yhujL6yflCOJ5NTU373H18S9XcPZIPoB54cZRtM8DMkdotXrzYky6VSsUdYVSUM1pR5vzOc99xvo63HG+JbJ/9SvF4TqRCyAns9XH+Hs/LkJGZzTYzCx8vp2+o6u189C2SdKlMipqpNVxXo5FUiVckq4zM7IdAIzDTzFqBvwQqANz928Angf9mZheALuDesJKJlDR3J0gHrFm4hvBvJpHYRFIQ3P3TI7z+TfqWpYrIAK+8/QrtZ9q13FQSQfcyEolRKtN3/YHeEEeSQAVBJEZBOmDu++ZyzZXXxB1FRAVBJC693ksqk9L8gSSGCoJITA6eOMhb776l4SJJDBUEkZgE6QDQ/IEkhwqCSEyCTMD7p7+fBdUL4o4iAqggiMSip7eH7ZntOjuQRFFBEInB/jf2c/rcaV1/IImigiASg/fmDxbqDEGSQwVBJAZBOuDamdcyu2p23FFE3qOCIJJn53vOs+v1XRouksRRQRDJsz1te3in+x0VBEkcFQSRPAvSAYZxx4I74o4ichEVBJE8S2VS3DT7JmZMnRF3FJGLqCCI5FFXdxdPH32aNfUaLpLkUUEQyaNnWp/hXM85zR9IIqkgiORRKp2i3Mq5fcHtcUcRuYQKgkgeBZmAZbXLeN9l74s7isglVBBE8uTMuTM82/ashosksSIpCGb2XTM7YWYvDvG6mdk3zOyImb1gZjdH0a9IIdn1+i4u9F7QDe0ksaI6Q/gX4M5hXv8YsCj8WA/8Q0T9ihSMVCZFRVkFK+evjDuKSFaRFAR33wGcHKbJOuD73mc3UG1mc6LoW6RQBOmA2+bdxtSKqXFHEcnK3D2aHZnVAz9z9+uzvPYz4FF33xU+/yXwVXffm6XtevrOIqipqVm6adOmSPJNlM7OTqqqquKOMSLljNZYc57pPsO6p9dx34L7uK/+vglMdrFiPZ5xKYScTU1N+9x92bi+2N0j+QDqgReHeO1JYNWA578Elo60z8WLF3vSpVKpuCOMinJGa6w5Nx/a7Hwd357ZPjGBhlCsxzMuhZAT2Ovj/D2er1VGrcC8Ac/nAu156lskdkE6oHJSJbfU3RJ3FJEh5asgbAE+F642uhU47e7H8tS3SOyCTMCq+au4bNJlcUcRGdKkKHZiZj8EGoGZZtYK/CVQAeDu3wa2AncBR4B3gT+Kol+RQnDinRO8eOJFPnP9Z+KOIjKsSAqCu396hNcd+JMo+hIpNM2ZZgBdkCaJpyuVRSZYkA6YNnkaS2uXxh1FZFgqCCITLJVJsXrBaiaVRXJCLjJhVBBEJlDrb1t55e1XNFwkBUEFQWQCpdIpQPMHUhhUEEQmUJAJuLLySm6cdWPcUURGpIIgMkHcnSAd0FjfSJnpv5okn35KRSZIuiPN66df1/snS8FQQRCZIEE6ADR/IIVDBUFkgqQyKWZXzeYDMz8QdxSRUVFBEJkA/fMHTfVNmFnccURGRQVBZAK8/NbLvNH5hoaLpKCoIIhMgFSm7/oDvX+yFBIVBJEJEKQD5l8xn6unXx13FJFRU0EQiViv95LKpFizcI3mD6SgqCCIRKzleAsnu05quEgKjgqCSMT6rz9QQZBCo4IgErEgE7DoykXMu2LeyI1FEkQFQSRCF3ovsD2zXctNpSBFUhDM7E4zO2xmR8zswSyvf97M3jSzA+HHF6PoVyRpnjv2HGfOn0nMcFFHVzcrHw1Y+OCTrHw0YPP+trgjSYLl/BZOZlYOfAv4KNAK7DGzLe7+0qCmP3L3+3PtTyTJ+ucPGusb4w0CbN7fRtupLto6ygFo6+jioSdaALh7SV2c0SShojhDWA4ccfdX3f088DiwLoL9ihScIB1w/VXXM6tqVtxR2LjtML3uF23r6u5h47bDMSWSpDMf9AMz5h2YfRK4092/GD7/LHDLwLMBM/s88AjwJvAK8D/c/egQ+1sPrAeoqalZumnTppzyTbTOzk6qqqrijjEi5YxWtpzdvd384VN/yF1z7uLL13w5pmS/09J2mlmVcLzr0tduqLsi/4GGUcjf96Rpamra5+7LxvO1Ubzrd7YrbwZXmX8Hfuju58zsS8D3gKyzbu7+GPAYQENDgzc2NkYQceI0NzeT9IygnFHLlnPnazs5t/Mcn1v1ORo/0Jj16/Lp4UcD7p13hr9tufi/eV11JQ/818Z4Qg2hkL/vxSSKIaNWYOD6urlA+8AG7v62u58Ln/4TsDSCfkUSJUgHGMYdC+6IOwoAG9Y2UDboSunKinI2rG2IKZEkXRQFYQ+wyMwWmtlk4F5gy8AGZjZnwNOPA4ci6FckUVKZFEvmLGF65fS4owB9E8d10yupq67E6DszeOSeGzShLEPKecjI3S+Y2f3ANqAc+K67HzSzvwL2uvsW4Mtm9nHgAnAS+Hyu/Yokybvd7/JM6zN8eXn8cwcDVVdW8NSDjXHHkAIRxRwC7r4V2Dpo29cGPH4IeCiKvkSS6OmjT3O+57wuSJOCpiuVRSKQSqeYVDaJVfNXxR1FZNxUEEQiEGQCPlz7YaZdNi3uKCLjpoIgkqPfnvste9r2aLhICp4KgkiOdr62kx7vUUGQgqeCIJKjVCbF5PLJ3Db3trijiOQkklVGIqUsSAesmLeCyorKuKMkwub9bWzcdpj2ji5qqyvZsLZB1z4UCJ0hiOTgZNdJDrxxgDX1Gi6CvmLw0BMttHV04fzuDqu67XZhUEEQycH2zHYcp2lhMt7/IG4btx2mq7vnom26w2rhUEEQyUGQDphaMZXldcvjjpII7R1Zbq06zHZJFhUEkRwEmYDb59/O5PLJcUdJhNrq7PMoQ22XZFFBEBmn453HeenNl0a93HTz/raifzvLDWsbqKwov2ib7rBaOLTKSGScUpkUwKjeP7l/srV/fL1Y386y/9+iVUaFSQVBZJyCdMAVl13BkjlLRmw73GRrsf2yvHtJXdH9m0qFhoxEximVSXFH/R1MKhv57ypNtkohUEEQGYfjZ49z5OSRUQ0XgSZbpTCoIIiMw/6O/QCjnlDWZKsUAs0hiIzD/o79zJw6k+uvun5U7TXZKoVABUFkjNydAx0HaHx/I2U2+pNsTbZK0kUyZGRmd5rZYTM7YmYPZnn9MjP7Ufj6r8ysPop+ReLwm1O/4cS5E7p/kRSdnAuCmZUD3wI+BnwQ+LSZfXBQsy8Ap9z9GuB/A3+da78icQnSATD6+QORQhHFGcJy4Ii7v+ru54HHgXWD2qwDvhc+/jHwETOzCPoWybtUJsWMyTNYPGNx3FFEIhXFHEIdcHTA81bglqHauPsFMzsNzADeGrwzM1sPrAeoqamhubk5gogTp7OzM/EZQTmj4u5sO7yNm6bdxPbt2+OOM6KkH89+ypkMURSEbH/p+zja9G10fwx4DKChocEbGxtzCjfRmpubSXpGUM6oHDxxkFM7TvHhmR9OdM5+ST+e/ZQzGaIYMmoF5g14PhdoH6qNmU0CrgBORtC3SF7137/o5uk3x5xEJHpRFIQ9wCIzW2hmk4F7gS2D2mwB7gsffxII3D3rGYJIkgXpgPrqemZPmR13FJHI5VwQ3P0CcD+wDTgEbHL3g2b2V2b28bDZd4AZZnYE+J/AJUtTRZKu13tpzjRruakUrUguTHP3rcDWQdu+NuDxWeBTUfQlEpfn33ieU2dP9S031YCnFCHdy0hklPqvP9D7J0uxUkEQGaUgE9Awo4HaabVxRxGZECoIIqPQ3dPNjtd26OpkKWoqCCKjsO/YPjrPd476/Q9ECpEKgsgo9M8fNNY3xhtEZAKpIIiMQpAOuHHWjdRcXhN3FJEJo4IgMoJzF87x1NGndP2BFD0VBJER7G7dzdkLZ7XcVIqeCoLICIJ0QJmVsXrB6rijiEwoFQSREaQyKZbOWUr1lOq4o4hMKBUEkWG8c/4ddrfu1nJTKQkqCCLDeOroU3T3duuCNCkJKggiw0ilU0wqm8Sq+avijiIy4SK526nIeG3e38bGbYdp7+iitrqSDTf1xB3pIkEm4Ja6W7h88uVxRxGZcDpDkNhs3t/GQ0+00NbRhQNtHV20nepi8/62uKMBcPrsafa279VwkZQMFQSJzcZth+nqvviMoNedjdsOx5ToYjte20Gv96ogSMlQQZDYtHd0jWl7vqUyKaZMmsKtc2+NO4pIXmgOQWJTW11JW5Zf/rXVlRPa7yXzFmsbuHtJ3SXtgnTAinkrmDJpyoTmEUmKnM4QzOxKM/u5mf06/Dx9iHY9ZnYg/NiSS59SPDasbaCyovyibWVmbFjbMGF9Zpu3eOiJlkvmLd569y2eP/687l8kJSXXIaMHgV+6+yLgl+HzbLrc/UPhx8dz7FOKxN1L6njknhuoq67EgLrqSuqmV2b9az0q2eYturp7Lpm32J7ZDqD5AykpuQ4ZrQMaw8ffA5qBr+a4Tykhdy+pu6gANDc3T2h/o523CNIBl1dczrLaZROaRyRJzN3H/8VmHe5ePeD5KXe/ZNjIzC4AB4ALwKPuvnmYfa4H1gPU1NQs3bRp07jz5UNnZydVVVVxxxiRcvY5/MYZzvf0XrJ9cnkZDbOnvff8vj33MWfKHB694dFYckZFOaNVCDmbmpr2ufu4/pIZ8QzBzH4BzM7y0sNj6Ge+u7eb2dVAYGYt7v6bbA3d/THgMYCGhgZvbGwcQzf519zcTNIzgnL26wjnEAYOG1VWlPPIPTfQGJ6pHDtzjNe3v84DKx+gcUX2LDqe0VLOZBixILj77w31mpkdN7M57n7MzOYAJ4bYR3v4+VUzawaWAFkLgshE6h+eGm6VUSqTAtAN7aTk5DqHsAW4D3g0/PzTwQ3ClUfvuvs5M5sJrAT+Jsd+RcZt8LzFYEE6oHpKNR+a/aE8phKJX66rjB4FPmpmvwY+Gj7HzJaZ2T+Hba4F9prZ80CKvjmEl3LsV2TCpDIpGusbKS8rH7mxSBHJ6QzB3d8GPpJl+17gi+Hjp4EbculHJF8yHRlePfUqf3bLn8UdRSTvdOsKkQFS6XD+QO+fLCVIBUFkgCATUDO1hutqros7ikjeqSCIhNydVDrFmoVrMLO444jknQqCSOjXJ39N25k2LTeVkqWCIBIK0gGg+xdJ6VJBEAmlMinmvm8u11x5TdxRRGKhgiAC9HovqXSKpvomzR9IyVJBEAEOnjjIm+++qeEiKWkqCCLo/kUioIIgAvRNKF89/WoWVC+IO4pIbFQQpOT19PbQnGnW22VKyVNBkJJ34I0DnD53WvMHUvJyvf21FJHN+9uGfZ+AYtV//YHuXySlTgVBgL5iMPCdxNo6unjoiRaAoi8KQSbg2pnXMrsq2xsDipQODRkJ0PcOYgPfVhKgq7uHjdsOx5QoP7p7utn52k4NF4mggiCh9o6uMW0vFnva9/BO9zsqCCKoIEiotrpyTNuLRZAOMIw7FtwRdxSR2KkgCAAb1jZQWXHxW0ZWVpSzYW1DTInyI0gH3DT7JmZMnRF3FJHY5VQQzOxTZnbQzHrNbNkw7e40s8NmdsTMHsylT5kYdy+p45F7bqCuuhID6qoreeSeG4p6QvnshbM8ffRpXX8gEsp1ldGLwD3APw7VwMzKgW8BHwVagT1mtsXdX8qx77wpleWYdy+pK8p/11CeOfoM53rOabmpSCinguDuh4CR7g65HDji7q+GbR8H1gEFURBKeTlmsQvSAeVWzuoFq+OOIpII5u6578SsGfhzd9+b5bVPAne6+xfD558FbnH3+4fY13pgPUBNTc3STZs25ZwvF4ffOMP5nt5Ltk8uL6Nh9jQ6OzupqqqKIdnYKOelHtj/AD3ew9/f/Pdj/lodz2gpZ3Sampr2ufuQQ/jDGfEMwcx+AWS7Yudhd//pKPrIdvowZBVy98eAxwAaGhq8sbFxFF1MnD968Ek8y1SLAelHG2lubibujKOhnBfrPN/JyztfZsOKDePqT8czWsqZDCMWBHf/vRz7aAXmDXg+F2jPcZ95U1tdSVuWtfjFvhyz2O16fRcXei/odtciA+Rj2ekeYJGZLTSzycC9wJY89BuJUl2OWexS6RQVZRWsnL8y7igiiZHrstNPmFkrcBvwpJltC7fXmtlWAHe/ANwPbAMOAZvc/WBusfOnFJdjloIgE3DbvNuYWjE17igiiZHrKqOfAD/Jsr0duGvA863A1lz6ilOpLccsdqe6TvHcsef4i9V/EXcUkUTRlcpScna8toNe79X9i0QGUUGQkpPKpKicVMktdbfEHUUkUVQQpOQE6YCV81dy2aTL4o4ikigqCFJS3nznTVpOtOj+RSJZqCBISWnONANo/kAkCxUEKSlBOmDa5GksrV0adxSRxFFBkJISZAJWL1jNpDK9nbjIYCoIUjLaftvGK2+/ouEikSGoIEjJSGVSgOYPRIaigiAlI0gHXFl5JTfOujHuKCKJpIIgJSOVSdFY30iZ6cdeJBv9z5CSkD6VJtOR0fUHIsNQQZCSEKQDAL1/ssgwVBCkJASZgFmXz+LamdfGHUUksbQYO6E2729j47bDtHd0UVtdyYa1DboF9zi5O6l0ijUL12CW7R1dRQRUEBJp8/42Hnqiha7uHgDaOrp46IkWABWFcTj89mGOdR7T22WKjEBDRgm0cdvh94pBv67uHjZuOxxTosLWP3+g6w9EhqeCkEDtHV1j2i7DS2VSzL9iPldPvzruKCKJlut7Kn/KzA6aWa+ZLRumXcbMWszsgJntzaXPUlBbXTmm7TK0Xu/V/IHIKOV6hvAicA+wYxRtm9z9Q+4+ZOGQPhvWNlBZUX7RtsqKcjasbYgpUeFqOd7C211va/5AZBRymlR290OA/vKKWP/EsVYZ5a7//kUqCCIjy9cqIwf+08wc+Ed3fyxP/Rasu5fUqQBEIEgHLLpyEfOumBd3FJHEM3cfvoHZL4DZWV562N1/GrZpBv7c3bPOD5hZrbu3m9lVwM+BB9w96zCTma0H1gPU1NQs3bRp02j/LbHo7Oykqqoq7hgjKsWcPd7DuqfW0XRVE19Z/JVI9tmvFI/nRFLO6DQ1Ne0b99C8u+f8ATQDy0bZ9uv0FY8R2y5evNiTLpVKxR1hVEox57Otzzpfxx9veTyyffYrxeM5kZQzOsBeH+fv8glfdmpml5vZtP7HwO/TNxktMqH6rz9orG+MN4hIgch12eknzKwVuA140sy2hdtrzWxr2GwWsMvMngeeBZ509/+XS78ioxFkAq6ruY5ZVbPijiJSEHJdZfQT4CdZtrcDd4WPXwVuyqUfkbE633OeXa/v4gtLvhB3FJGCoSuVpSg92/Ys73a/q9tViIyBCoIUpSAdYBh3LLgj7igiBUMFQYpSkA5YMmcJ0yunxx1FpGCoIEjR6eru4pnWZ/R2mSJjpIIgRefpo09zvue85g9ExkgFQYpOkA4ot3JWzV8VdxSRgqKCIEUnlUmxvG450y6bFncUkYKigiBF5cy5Mzzb9qyGi0TGQQVBisrO13fS4z263bXIOKggSFFJpVNMLp/Minkr4o4iUnBUEKSoBJmAFfNWUFmhtxsVGSsVBCkaJ7tOsv/Yfl1/IDJOKghSNLZntuM4TQs1fyAyHioIUjRSmRRTK6ayvG553FFECpIKghSNIB1w+/zbmVw+Oe4oIgVJBUGKwvHO4xx886CWm4rkQAVBikJzphlAF6SJ5EAFQYpCkA644rIrWDJnSdxRRAqWCoIUhSATsHrBaiaV5fSusCIlLaeCYGYbzexlM3vBzH5iZtVDtLvTzA6b2REzezCXPkUGO3r6KEdOHtFwkUiOcj1D+DlwvbvfCLwCPDS4gZmVA98CPgZ8EPi0mX0wx35F3pPKpADNH4jkKqeC4O7/6e4Xwqe7gblZmi0Hjrj7q+5+HngcWJdLvyIDBemAGZUzuP6q6+OOIlLQohxw/WPgR1m21wFHBzxvBW4Zaidmth5YHz49Z2YvRpZwYswE3oo7xCgUfc7yr5ZHHGVYRX8880w5o9Mw3i8csSCY2S+A2Vleetjdfxq2eRi4APwg2y6ybPOh+nP3x4DHwv3udfdlI2WMUyFkBOWMmnJGSzmjY2Z7x/u1IxYEd/+9ETq/D/gD4CPunu0XfSswb8DzuUD7WEKKiMjEy3WV0Z3AV4GPu/u7QzTbAywys4VmNhm4F9iSS78iIhK9XFcZfROYBvzczA6Y2bcBzKzWzLYChJPO9wPbgEPAJnc/OMr9P5ZjvnwohIygnFFTzmgpZ3TGndGyj/KIiEip0ZXKIiICqCCIiEgoUQWhEG6FYWafMrODZtZrZkMuPzOzjJm1hHMr414GNl5jyBnrbUXM7Eoz+7mZ/Tr8PH2Idj3hsTxgZnlblDDS8TGzy8zsR+HrvzKz+nxlG5RjpJyfN7M3BxzDL8aQ8btmdmKoa4uszzfCf8MLZnZzvjOGOUbK2Whmpwccy6/FkHGemaXM7FD4//xPs7QZ+/F098R8AL8PTAof/zXw11nalAO/Aa4GJgPPAx/MY8Zr6bvwoxlYNky7DDAzxmM5Ys64j2WY4W+AB8PHD2b7noevdcZwDEc8PsB/B74dPr4X+FFCc34e+Ga+sw3KsBq4GXhxiNfvAv6DvmuXbgV+ldCcjcDPYj6Wc4Cbw8fT6Lt10ODv+ZiPZ6LOELwAboXh7ofc/XC++huvUeZMwm1F1gHfCx9/D7g7z/0PZzTHZ2D+HwMfMbNsF2NOpCR8H0fk7juAk8M0WQd83/vsBqrNbE5+0v3OKHLGzt2Puftz4eMz9K3grBvUbMzHM1EFYZA/pq+6DZbtVhiDD0QSOPCfZrYvvB1HEiXhWM5y92PQ90MOXDVEuylmttfMdptZvorGaI7Pe23CP2ZOAzPyki5LhtBQ38f/Eg4d/NjM5mV5PW5J+HkcrdvM7Hkz+w8zuy7OIOEw5RLgV4NeGvPxzPvN4/N9K4zxGE3GUVjp7u1mdhV912m8HP7lEZkIck74sYThc45hN/PD43k1EJhZi7v/JpqEQxrN8cnLMRzBaDL8O/BDdz9nZl+i76wmabeHTcKxHI3ngAXu3mlmdwGbgUVxBDGzKuDfgD9z998OfjnLlwx7PPNeELwAboUxUsZR7qM9/HzCzH5C32l9pAUhgpx5ua3IcDnN7LiZzXH3Y+Hp7Ikh9tF/PF81s2b6/iKa6IIwmuPT36bVzCYBV5D/4YYRc7r72wOe/hN9c3RJUxC3uRn4i9fdt5rZ35vZTHfP603vzKyCvmLwA3d/IkuTMR/PRA0ZWZHcCsPMLjezaUnZMWUAAAFMSURBVP2P6ZssT+JdW5NwLLcA94WP7wMuObMxs+lmdln4eCawEngpD9lGc3wG5v8kEAzxh8xEGjHnoLHjj9M35pw0W4DPhatjbgVO9w8nJomZze6fJzKz5fT9Hn17+K+KPIMB3wEOufvfDdFs7MczzpnyLDPnR+gb8zoQfvSv3qgFtg6aPX+Fvr8QH85zxk/QV3nPAceBbYMz0rfa4/nw42C+M442Z9zHMux/BvBL4Nfh5yvD7cuAfw4frwBawuPZAnwhj/kuOT7AX9H3RwvAFOD/hj+7zwJX5/sYjjLnI+HP4vNACvhADBl/CBwDusOfzS8AXwK+FL5u9L2Z1m/C7/OQq/hiznn/gGO5G1gRQ8ZV9A3/vDDg9+VduR5P3bpCRESAhA0ZiYhIfFQQREQEUEEQEZGQCoKIiAAqCCIiElJBEBERQAVBRERC/x8yNpoX5yKDyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.grid()\n",
    "\n",
    "plt.xlim(-2, 2)\n",
    "plt.ylim(-2, 2)\n",
    "\n",
    "plt.plot([-2, 2], list(map(lambda x: x * 6, [-2, 2])), c='g');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем единичный вектор, на который будем проецировать вектор X. Тогда проекция на него будет равна $v^TX$. Дисперсия проекции на вектор будет соответственно равна $Var(v^TX)$. В общем виде в векторной форме (для центрированных величин) дисперсия выражается так:\n",
    "\n",
    "$$Var(X) = \\frac{1}{n}\\sum_{i, j}^n{x_{ij} \\cdot x^T_{ij}} = E(X \\cdot X^T)$$\n",
    "\n",
    "Дисперсия проекции:\n",
    "$$Var(X^*) = E(X^* \\cdot X^{*T}) = E((v^TX) \\cdot (v^TX)^T) = E(v^TX \\cdot X^Tv) = v^TE(X \\cdot X^T)v$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дисперсия максимизируется при максимальном значении. У отношения Рэлея есть специальный случай для ковариационных матриц:\n",
    "\n",
    "$$R(A, v) = \\frac{v^TAv}{v^Tv} = \\lambda \\frac{v^Tv}{v^Tv} = \\lambda$$\n",
    "\n",
    "$$Av = \\lambda v$$\n",
    "\n",
    "Эта формула - разложение матрицы на собственные вектора и значения. v - собственный вектор, а λ – собственное значение. Количество собственных векторов и значений равны размеру матрицы.\n",
    "\n",
    "Таким образом, направление максимальной дисперсии у проекции всегда совпадает с собственным вектором, имеющим максимальное собственное значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.4963641,  0.5036359])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.70710678, -0.70710678],\n",
       "       [ 0.70710678,  0.70710678]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eig_val, eig_vecs = np.linalg.eig(X.T @ X)\n",
    "display(eig_val, eig_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.70710678, 0.70710678]), array([-0.70710678,  0.70710678]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec0 = eig_vecs[:, 0]\n",
    "vec1 = eig_vecs[:, 1]\n",
    "vec0, vec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.grid()\n",
    "\n",
    "plt.xlim(-2, 2)\n",
    "plt.ylim(-2, 2)\n",
    "\n",
    "plt.plot([0, vec0[0]], [0, vec0[1]], c='r')\n",
    "plt.plot([0, vec1[0]], [0, vec1[1]], c='g');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто требуется оценить объем потерянной (и сохраненной) информации. Удобнее всего представить в процентах. Берем дисперсию по каждой из осей и делим на общую сумму дисперсий по осям (т.е. сумму всех собственных значений)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[97.48182049145893, 2.518179508541074]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_sum = sum(eig_val)\n",
    "[(i / eig_sum) * 100 for i in sorted(eig_val, reverse=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, наш больший вектор описывает 97.48%, а меньший, соответственно, 2.51%. Отбросив меньший вектор и спроецировав данные на больший, мы потеряем меньше 3% информации.\n",
    "\n",
    "На практике, если суммарная потеря информации составляет не более 10-20%, то можно спокойно снижать размерность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно спроецировать данные на вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.8199141 , -1.85932034, -1.24301832, -0.65735334, -0.45968116,\n",
       "        0.22878749,  0.72119107,  0.78121433,  1.9589893 ,  2.34910508])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = vec0\n",
    "Z = np.dot(X, v)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.8199141 ],\n",
       "       [-1.85932034],\n",
       "       [-1.24301832],\n",
       "       [-0.65735334],\n",
       "       [-0.45968116],\n",
       "       [ 0.22878749],\n",
       "       [ 0.72119107],\n",
       "       [ 0.78121433],\n",
       "       [ 1.9589893 ],\n",
       "       [ 2.34910508]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linalg.eig(X.T @ X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z.T @ Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvLN4XJLdfJx"
   },
   "source": [
    "Некоторые полезные свойства метода:\n",
    "\n",
    "- Матрица $Z$ при этом будет такой, что $Z^{T}Z = \\Lambda = diag(\\lambda_{1},...,\\lambda_{d})$.\n",
    "\n",
    "\n",
    "- Минимизированный функционал ошибки будет равен $$\\|ZW - X\\|^{2} = \\|X\\|^{2} - tr\\Lambda,$$ где $tr\\Lambda,$ - след матрицы $\\Lambda$, то есть сумма всех собственных значений $\\lambda_{1},...,\\lambda_{d}$, а $\\|X\\|^{2}$ - сумма всех собственных значений исходной матрицы $\\lambda_{1},...,\\lambda_{n}$, таким образом $$\\|ZW - X\\|^{2} = \\sum_{j=d+1}^{n}\\lambda_{j},$$ то есть значение функционала ошибки будет равно сумме собственных значений, которые не были взяты в получаемое разложение. Поэтому логично брать в разложение максимальные собственные значения, оставляя минимальные.\n",
    "\n",
    "\n",
    "- Матрица $X^{T}X$ - матрица ковариации, то есть матрица, которая характеризует дисперсию выборки. Дисперсия выборки после проецирования будет равна собственному значению $\\lambda$, поэтому логично, что первым берется собственный вектор, соответствующий максимальному собственному значению - нам нужно сохранить максимум дисперсии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pPzjbW8dfJy"
   },
   "source": [
    "Таким образом, для реализации метода главных компонент нужно :\n",
    "- найти собственные значения матрицы $X^{T}X$;\n",
    "- отобрать $d$ максимальных;\n",
    "- составить матрицу $W^{T}$, столбцы которой будут являться собственными векторами, соответствующими отобранным собственным значениям, расположенным в порядке убывания;\n",
    "- получить новую матрицу \"объекты-признаки\", умножив исходную матрицу $X$ на матрицу весов $W$ :\n",
    "\n",
    "$$Z=XW.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnYvDiOadfJz"
   },
   "source": [
    "#### PCA и SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Thkg-tSXdfJ0"
   },
   "source": [
    "Сформулировав принцип реализации метода главных компонент, нельзя не заметить его родство с сингулярным разложением матриц (SVD). Вспомним, что сингулярное разложение матрицы - это разложение вида\n",
    "\n",
    "$$X=UDV^{T},$$\n",
    "\n",
    "- столбцы ортогональной матрицы $U$ - это собственные векторы матрицы $XX^{T}$\n",
    "- столбцы ортогональной матрицы $V$ - собственные векторы матрицы $X^{T}X$\n",
    "- на главной диагонали диагональной матрицы $D$ расположены собственные значения матриц $XX^{T}$ и $X^{T}X$ (они равны и также называются сингулярными числами матрицы $X$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tzfpn9zdfJ0"
   },
   "source": [
    "Таким образом, для реализации понижения размерности методом главных компонент с помощью SVD нужно:\n",
    "- найти сингулярное разложение $X^TX$;\n",
    "- сформировать из столбцов матрицы $V$, соответствующих $d$ наибольшим сингулярным числам, матрицу весов $W$;\n",
    "- получить новую матрицу \"объекты-признаки\", умножив исходную матрицу $X$ на матрицу весов $W$:\n",
    "\n",
    "$$Z=XW.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWEQalcAdfJ1"
   },
   "source": [
    "Для закрепления теории реализуем PCA с помощью Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример на ирисах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "m3d93Gx2dfJ6",
    "outputId": "eaee1c83-f56e-474c-a5f2-bdd5d4659ab4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузим игрушечный датасет из sklearn\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для начала отмасштабируем выборку\n",
    "X = X.astype(float)\n",
    "\n",
    "X = standard_scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90068117,  1.01900435, -1.34022653, -1.3154443 ],\n",
       "       [-1.14301691, -0.13197948, -1.34022653, -1.3154443 ],\n",
       "       [-1.38535265,  0.32841405, -1.39706395, -1.3154443 ],\n",
       "       [-1.50652052,  0.09821729, -1.2833891 , -1.3154443 ],\n",
       "       [-1.02184904,  1.24920112, -1.34022653, -1.3154443 ],\n",
       "       [-0.53717756,  1.93979142, -1.16971425, -1.05217993],\n",
       "       [-1.50652052,  0.78880759, -1.34022653, -1.18381211],\n",
       "       [-1.02184904,  0.78880759, -1.2833891 , -1.3154443 ],\n",
       "       [-1.74885626, -0.36217625, -1.34022653, -1.3154443 ],\n",
       "       [-1.14301691,  0.09821729, -1.2833891 , -1.44707648]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ItFOmLW9dfKB",
    "outputId": "0b507805-c106-4539-d15a-4dc8327b764f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собственные значения и собственные векторы в порядке убывания:\n",
      "(437.77467247979894, array([ 0.52106591, -0.26934744,  0.5804131 ,  0.56485654]))\n",
      "(137.10457072021055, array([-0.37741762, -0.92329566, -0.02449161, -0.06694199]))\n",
      "(22.01353133569725, array([-0.71956635,  0.24438178,  0.14212637,  0.63427274]))\n",
      "(3.1072254642929513, array([ 0.26128628, -0.12350962, -0.80144925,  0.52359713]))\n"
     ]
    }
   ],
   "source": [
    "# Найдем собственные векторы и собственные значения\n",
    " \n",
    "covariance_matrix = X.T @ X\n",
    "\n",
    "eig_values, eig_vectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "# сформируем список кортежей (собственное значение, собственный вектор)\n",
    "eig_pairs = [(np.abs(eig_values[i]), eig_vectors[:, i]) for i in range(len(eig_values))]\n",
    "\n",
    "# и отсортируем список по убыванию собственных значений\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print('Собственные значения и собственные векторы в порядке убывания:')\n",
    "for i in eig_pairs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mdEDwm2dfKD"
   },
   "source": [
    "Оценим долю дисперсии, которая описывается найденными компонентами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Ct-1I70mdfKE",
    "outputId": "ab04c5c2-649d-4f6f-e849-3791203481d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля дисперсии, описываемая каждой из компонент \n",
      "[72.96244541329986, 22.85076178670177, 3.668921889282877, 0.5178709107154922]\n",
      "Кумулятивная доля дисперсии по компонентам \n",
      "[ 72.96244541  95.8132072   99.48212909 100.        ]\n"
     ]
    }
   ],
   "source": [
    "eig_sum = sum(eig_values)\n",
    "var_exp = [(i / eig_sum) * 100 for i in sorted(eig_values, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(f'Доля дисперсии, описываемая каждой из компонент \\n{var_exp}')\n",
    "\n",
    "# а теперь оценим кумулятивную (то есть накапливаемую) дисперсию при учитывании каждой из компонент\n",
    "print(f'Кумулятивная доля дисперсии по компонентам \\n{cum_var_exp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NE15sfLtdfKH"
   },
   "source": [
    "Таким образом, первая главная компонента описывает почти 73% информации, а первые две в сумме - 95.8%. В то же время последняя компонента описывает всего 0.5% и может быть отброжена без страха значительных потерь в качестве нашего анализа. Мы отбросим последние две компоненты, оставив первые две."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "z4xcGvf7dfKI",
    "outputId": "e406100f-3bd4-40fb-ce09-15db12e77a12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица весов W:\n",
      " [[ 0.52106591 -0.37741762]\n",
      " [-0.26934744 -0.92329566]\n",
      " [ 0.5804131  -0.02449161]\n",
      " [ 0.56485654 -0.06694199]]\n"
     ]
    }
   ],
   "source": [
    "# Сформируем вектор весов из собственных векторов, соответствующих первым двум главным компонентам\n",
    "W = np.hstack([eig_pairs[i][1].reshape(4,1) for i in range(2)])\n",
    "\n",
    "print(f'Матрица весов W:\\n', W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "n04tyd6xdfKL"
   },
   "outputs": [],
   "source": [
    "# Сформируем новую матрицу \"объекты-признаки\"\n",
    "Z = X.dot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.26470281, -0.4800266 ],\n",
       "       [-2.08096115,  0.67413356],\n",
       "       [-2.36422905,  0.34190802],\n",
       "       [-2.29938422,  0.59739451],\n",
       "       [-2.38984217, -0.64683538],\n",
       "       [-2.07563095, -1.48917752],\n",
       "       [-2.44402884, -0.0476442 ],\n",
       "       [-2.23284716, -0.22314807],\n",
       "       [-2.33464048,  1.11532768],\n",
       "       [-2.18432817,  0.46901356]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "CBqTYO6udfKO",
    "outputId": "8e8e6a9d-f8fa-4c1a-ea3f-84a9bd859bed"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "y = iris.target\n",
    "for c, i in zip(\"rgb\", [0, 1, 2]):\n",
    "    plt.scatter(Z[y == i, 0], Z[y == i, 1], c=c)\n",
    "plt.xlabel('Главная компонента 1')\n",
    "plt.ylabel('Главная компонента 2')\n",
    "plt.title('PCA датасета IRIS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7P4Be8PdfKQ"
   },
   "source": [
    "Таким образом, мы перешли от четырехмерного пространства признаков к двумерному и при этом классы остались разделимы в пространстве, то есть классификация возможна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание<a class='anchor' id='hw'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Обучить любую модель классификации на датасете IRIS до применения PCA (2 компоненты) и после него. Сравнить качество классификации по отложенной выборке.\n",
    "2. *Написать свою реализацию метода главных компонент с помощью сингулярного разложения с использованием функции [numpy.linalg.svd()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPCA:\n",
    "    \n",
    "    def __init__(self, n_components=None):\n",
    "        self.__n_components = n_components\n",
    "    \n",
    "    def __get_n_components(self, X):\n",
    "        n = self.__n_components\n",
    "        if n == None:\n",
    "            n == X.shape[1]\n",
    "        return n\n",
    "    \n",
    "    def __set_exp_var(self, exp_var):\n",
    "        self.exp_var_ = exp_var\n",
    "        \n",
    "    def __set_cum_exp_var(self, cum_exp_var):\n",
    "        self.cum_exp_var_ = cum_exp_var\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        n = self.__get_n_components(X)\n",
    "        U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "        V = Vt.T\n",
    "        S = np.diag(s)\n",
    "        exp_var = np.round(s**2/np.sum(s**2), decimals=4)[:n]\n",
    "        cum_exp_var = np.cumsum(exp_var)\n",
    "        self.__set_exp_var(exp_var)\n",
    "        self.__set_cum_exp_var(cum_exp_var)\n",
    "        X_transformed = U[:, 0:n].dot(S[0:n, 0:n])\n",
    "        return X_transformed\n",
    "    \n",
    "# Реализуем класс узла\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле\n",
    "        \n",
    "# И класс терминального узла (листа)\n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction_classification = self.predict()\n",
    "        self.prediction_regression = self.predict_reg()\n",
    "        \n",
    "    def predict(self):\n",
    "        # подсчет количества объектов разных классов\n",
    "        classes = {}  # сформируем словарь \"класс: количество объектов\"\n",
    "        for label in self.labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "        #  найдем класс, количество объектов которого будет максимальным в этом листе и вернем его    \n",
    "        prediction = max(classes, key=classes.get)\n",
    "        return prediction  \n",
    "\n",
    "    def predict_reg(self):\n",
    "        #  найдем значение как среднее по выборке   \n",
    "        prediction = np.mean(self.labels)\n",
    "        return prediction\n",
    "    \n",
    "# Расчет критерия Джини\n",
    "def gini(labels):\n",
    "    #  подсчет количества объектов разных классов\n",
    "    classes = {}\n",
    "    for label in labels:\n",
    "        if label not in classes:\n",
    "            classes[label] = 0\n",
    "        classes[label] += 1\n",
    "    \n",
    "    #  расчет критерия\n",
    "    impurity = 1\n",
    "    for label in classes:\n",
    "        p = classes[label] / len(labels)\n",
    "        impurity -= p ** 2\n",
    "        \n",
    "    return impurity\n",
    "\n",
    "# Расчет качества для задачи классификации\n",
    "def quality(left_labels, right_labels, current_gini):\n",
    "\n",
    "    # доля выбоки, ушедшая в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "    \n",
    "    return current_gini - p * gini(left_labels) - (1 - p) * gini(right_labels)\n",
    "\n",
    "# Разбиение датасета в узле\n",
    "def split(data, labels, index, t):\n",
    "    \n",
    "    left = np.where(data[:, index] <= t)\n",
    "    right = np.where(data[:, index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels\n",
    "\n",
    "# Нахождение наилучшего разбиения для задачи классификации\n",
    "def find_best_split(data, labels):\n",
    "    \n",
    "    #  обозначим минимальное количество объектов в узле\n",
    "    min_leaf = 5\n",
    "\n",
    "    current_gini = gini(labels)\n",
    "\n",
    "    best_quality = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    for index in range(n_features):\n",
    "        # будем проверять только уникальные значения признака, исключая повторения\n",
    "        t_values = np.unique([row[index] for row in data])\n",
    "        \n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "            if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
    "                continue\n",
    "            \n",
    "            current_quality = quality(true_labels, false_labels, current_gini)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_quality > best_quality:\n",
    "                best_quality, best_t, best_index = current_quality, t, index\n",
    "\n",
    "    return best_quality, best_t, best_index\n",
    "\n",
    "# Построение дерева классификации с помощью рекурсивной функции\n",
    "def build_tree_classification(data, labels, tree_depth=1, max_depth=50):\n",
    "\n",
    "    quality, t, index = find_best_split(data, labels)\n",
    "\n",
    "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "    if quality == 0:\n",
    "        return Leaf(data, labels)\n",
    "\n",
    "    # Базовый случай (2) - прекращаем рекурсию, когда достигнута максимальная глубина дерева\n",
    "    if tree_depth >= max_depth:\n",
    "        return Leaf(data, labels)\n",
    "\n",
    "    # Увеличиваем глубину дерева на 1\n",
    "    tree_depth += 1\n",
    "\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "\n",
    "    # Рекурсивно строим два поддерева\n",
    "    true_branch = build_tree_classification(true_data, true_labels, tree_depth, max_depth)\n",
    "    false_branch = build_tree_classification(false_data, false_labels, tree_depth, max_depth)\n",
    "\n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return Node(index, t, true_branch, false_branch)\n",
    "\n",
    "def classify_object(obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf):\n",
    "        answer = node.prediction_classification\n",
    "        return answer\n",
    "\n",
    "    if obj[node.index] <= node.t:\n",
    "        return classify_object(obj, node.true_branch)\n",
    "    else:\n",
    "        return classify_object(obj, node.false_branch)\n",
    "    \n",
    "def predict_class(data, tree):\n",
    "    \n",
    "    classes = []\n",
    "    for obj in data:\n",
    "        prediction = classify_object(obj, tree)\n",
    "        classes.append(prediction)\n",
    "    return classes\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (original train data): 0.7733\n",
      "Accuracy score (original test data): 0.1867\n"
     ]
    }
   ],
   "source": [
    "custom_tree = build_tree_classification(X_train, y_train, max_depth=3)\n",
    "\n",
    "y_train_pred = predict_class(X_train, custom_tree)\n",
    "y_test_pred = predict_class(X_test, custom_tree)\n",
    "\n",
    "print(f'Accuracy score (original train data): {np.round(accuracy(y_train, y_train_pred), 4)}')\n",
    "print(f'Accuracy score (original test data): {np.round(accuracy(y_test, y_test_pred), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pca = CustomPCA(n_components=3)\n",
    "\n",
    "X_pca = custom_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (pca train data): 0.78\n",
      "Accuracy score (pca test data): 0.1933\n"
     ]
    }
   ],
   "source": [
    "custom_tree = build_tree_classification(X_train, y_train, max_depth=3)\n",
    "\n",
    "y_train_pred = predict_class(X_train, custom_tree)\n",
    "y_test_pred = predict_class(X_test, custom_tree)\n",
    "\n",
    "print(f'Accuracy score (pca train data): {np.round(accuracy(y_train, y_train_pred), 4)}')\n",
    "print(f'Accuracy score (pca test data): {np.round(accuracy(y_test, y_test_pred), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проект: \n",
    "1. https://www.kaggle.com/c/regression-tutors-expected-math-exam-results регрессия\n",
    "1. https://www.kaggle.com/c/classification-choose-tutors классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6YHvcPvdfKS"
   },
   "source": [
    "## Дополнительные материалы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQKbma5FdfKT"
   },
   "source": [
    "1. [Методы отбора признаков](https://habr.com/ru/company/aligntechnology/blog/303750/)\n",
    "2. [Взаимная информация](https://ru.wikipedia.org/wiki/%D0%92%D0%B7%D0%B0%D0%B8%D0%BC%D0%BD%D0%B0%D1%8F_%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D1%8F)\n",
    "3. [Методы понижения размерности](http://www.machinelearning.ru/wiki/images/0/06/SLT%2C_lecture_8.pdf)\n",
    "4. [Лемма о малом искажении](https://ru.wikipedia.org/wiki/%D0%9B%D0%B5%D0%BC%D0%BC%D0%B0_%D0%BE_%D0%BC%D0%B0%D0%BB%D0%BE%D0%BC_%D0%B8%D1%81%D0%BA%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B8)\n",
    "5. [PCA from Scratch in Python](https://github.com/bhattbhavesh91/pca-from-scratch-iris-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Снижать размерность данных можно за счет\n",
    "    * отбора признаков (корреляция, взаимная информация, переборные методы, вес коэфф. регрессии, feature_importances и др.)\n",
    "    * понижения размерности (случайные проекции, PCA, ICA (Independent Component Analysis), NMF (Non-negative Matrix Factorization) и др.)\n",
    "* Уменьшение размерности \n",
    "    * ускоряет работу моделей\n",
    "    * улучшает интерпретируемость решения\n",
    "    * улучшает точность модели, если были удалены шумовые и нерелевантные признаки\n",
    "* В основе PCA используется понятие [_собственного вектора_](https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D0%B1%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B2%D0%B5%D0%BA%D1%82%D0%BE%D1%80) - это вектор, умножение которого на матрицу даёт коллинеарный вектор - тот же вектор, умноженный на некоторое число, называемое _собственным значением_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определения\n",
    "*Снижение размерности*\n",
    "\n",
    "**Снижение размерности** — это преобразование данных, состоящее в уменьшении числа переменных.\n",
    "\n",
    "**Одномерный отбор признаков** — оценка предсказательной силы каждого признака (насколько он коррелирует с целевой переменной).\n",
    "\n",
    "**Корреляция** — статистическая взаимосвязь двух или более случайных величин.\n",
    "\n",
    "**Взаимная информация** — статистическая функция двух случайных величин, описывающая количество информации, содержащееся в одной случайной величине относительно другой.\n",
    "\n",
    "**Понижение размерности** — это преобразование данных, состоящее в уменьшении числа переменных путём получения новых переменных.\n",
    "\n",
    "**Метод главных компонент** — один из основных способов уменьшить размерность данных, потеряв наименьшее количество информации. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson_8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
