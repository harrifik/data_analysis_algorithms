{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Практическая часть<a class=\"anchor\" id=\"practice\"></a><center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zhwkeWtb1O0w"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FeKFn2yb1To4"
   },
   "outputs": [],
   "source": [
    "X = np.array([ [   1,    1,  500,    1],\n",
    "               [   1,    1,  700,    1],\n",
    "               [   1,    2,  750,    2],\n",
    "               [   1,    5,  600,    1],\n",
    "               [   1,    3, 1450,    2],\n",
    "               [   1,    0,  800,    1],\n",
    "               [   1,    5, 1500,    3],\n",
    "               [   1,   10, 2000,    3],\n",
    "               [   1,    1,  450,    1],\n",
    "               [   1,    2, 1000,    2]], dtype = np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "yXSj4nbxHsFd",
    "outputId": "8d102d54-94bf-4acc-d5b8-d60da152b953",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00e+00, 1.00e+00, 5.00e+02, 1.00e+00],\n",
       "       [1.00e+00, 1.00e+00, 7.00e+02, 1.00e+00],\n",
       "       [1.00e+00, 2.00e+00, 7.50e+02, 2.00e+00],\n",
       "       [1.00e+00, 5.00e+00, 6.00e+02, 1.00e+00],\n",
       "       [1.00e+00, 3.00e+00, 1.45e+03, 2.00e+00],\n",
       "       [1.00e+00, 0.00e+00, 8.00e+02, 1.00e+00],\n",
       "       [1.00e+00, 5.00e+00, 1.50e+03, 3.00e+00],\n",
       "       [1.00e+00, 1.00e+01, 2.00e+03, 3.00e+00],\n",
       "       [1.00e+00, 1.00e+00, 4.50e+02, 1.00e+00],\n",
       "       [1.00e+00, 2.00e+00, 1.00e+03, 2.00e+00]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QU0A16vZHugZ",
    "outputId": "71d74b95-77f4-41a7-e339-c9e7b2004e4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-aO1NTxOUfo"
   },
   "outputs": [],
   "source": [
    "def standard_scale(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8EL0iGJOVpe"
   },
   "outputs": [],
   "source": [
    "X_st = X.copy()\n",
    "X_st[:, 2] = standard_scale(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "gviMxz7EOuI3",
    "outputId": "af9a2576-f4d7-41d7-e216-46e0a068cfad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        , -0.97958969,  1.        ],\n",
       "       [ 1.        ,  1.        , -0.56713087,  1.        ],\n",
       "       [ 1.        ,  2.        , -0.46401617,  2.        ],\n",
       "       [ 1.        ,  5.        , -0.77336028,  1.        ],\n",
       "       [ 1.        ,  3.        ,  0.97958969,  2.        ],\n",
       "       [ 1.        ,  0.        , -0.36090146,  1.        ],\n",
       "       [ 1.        ,  5.        ,  1.08270439,  3.        ],\n",
       "       [ 1.        , 10.        ,  2.11385144,  3.        ],\n",
       "       [ 1.        ,  1.        , -1.08270439,  1.        ],\n",
       "       [ 1.        ,  2.        ,  0.05155735,  2.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMR5pOA38dDw"
   },
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R6zfOHMrBvnX",
    "outputId": "46df0625-963f-4401-da30-b5b42bcf1be7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.164252033486018"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример применения\n",
    "y1 = np.array([1, 0])\n",
    "y_pred1 = np.array([0.8, 0.1])\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Плохой пример применения\n",
    "y1 = np.array([1, 0])\n",
    "y_pred1 = np.array([1, 0.1])\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEF9rWPNDnss"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9tN8lBEEeXU"
   },
   "outputs": [],
   "source": [
    "z = np.linspace(-10, 10, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nvIe3RpbEp4l"
   },
   "outputs": [],
   "source": [
    "probabilities = sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "jQsCfht0Et1V",
    "outputId": "0c11fcdd-1cf9-49db-aaa7-4fa520ff840a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, probabilities)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e6TH-mkPItb6"
   },
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtgUN3LW-UIq"
   },
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, eta=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z = np.dot(X, W)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        \n",
    "        dQ = 1/n * X.T @ (y_pred - y)\n",
    "        W -= eta * dQ\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, W, err)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "oqX7loklBmYZ",
    "outputId": "f4849295-1f14-40d8-c8f2-d1b002e130c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.49667621 -0.13840939  0.6476858   1.52297324] 1.1785958344356262\n",
      "50 [ 0.494784   -0.14564801  0.6475462   1.52014828] 1.1657985749255426\n",
      "100 [ 0.49290109 -0.15285535  0.64740132  1.51733474] 1.1531112685708473\n",
      "150 [ 0.49102761 -0.16003088  0.64725118  1.51453281] 1.1405352753305018\n",
      "200 [ 0.48916364 -0.16717404  0.64709581  1.51174267] 1.1280719326917483\n",
      "250 [ 0.48730929 -0.17428428  0.64693524  1.50896452] 1.1157225565960736\n",
      "300 [ 0.48546465 -0.18136107  0.64676951  1.50619853] 1.103488442622439\n",
      "350 [ 0.48362982 -0.18840385  0.64659868  1.5034449 ] 1.0913708674192037\n",
      "400 [ 0.48180488 -0.19541206  0.64642281  1.50070383] 1.0793710903721336\n",
      "450 [ 0.47998993 -0.20238516  0.64624195  1.49797551] 1.0674903554915993\n"
     ]
    }
   ],
   "source": [
    "W = eval_model(X_st, y, iterations=500, eta=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.         -0.97958969  1.        ]\n",
      " [ 1.          1.         -0.56713087  1.        ]\n",
      " [ 1.          2.         -0.46401617  2.        ]\n",
      " [ 1.          5.         -0.77336028  1.        ]\n",
      " [ 1.          3.          0.97958969  2.        ]\n",
      " [ 1.          0.         -0.36090146  1.        ]\n",
      " [ 1.          5.          1.08270439  3.        ]\n",
      " [ 1.         10.          2.11385144  3.        ]\n",
      " [ 1.          1.         -1.08270439  1.        ]\n",
      " [ 1.          2.          0.05155735  2.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание <a class='anchor' id='hw'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. *Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss_mod(y, y_pred):\n",
    "    err = - np.mean(y*np.log(y_pred + 1e-16) + (1.0 - y)*np.log(1.0 - y_pred + 1e-16))\n",
    "    return np.sum(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check with zeros: 0.0\n",
      "calc_logloss: nan, calc_logloss_mod: 0.05268025782891308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(f'Check with zeros: {calc_logloss_mod(np.array([0, 0]), np.array([0.0, 0.0]))}')\n",
    "print(f'calc_logloss: {calc_logloss(y1, y_pred1)}, calc_logloss_mod: {calc_logloss_mod(y1, y_pred1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_eval_model_mod(X, y, iterations, alpha=1e-4, verbose=False):\n",
    "    np.random.seed(2020)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W -= alpha*(1/n * np.dot((y_pred - y), X.T))\n",
    "        \n",
    "        if verbose:\n",
    "            if i % (iterations/10) == 0 :\n",
    "                print(f'итерация: {i}, logloss: {err}, веса: {W}')\n",
    "            \n",
    "    return W, err\n",
    "\n",
    "def optimize(func, X, y, iter_list, alpha_list):\n",
    "    d = {}\n",
    "    for iteration in iter_list:\n",
    "        for alpha in alpha_list:\n",
    "            W, err = func(X, y, iterations=iteration, alpha=alpha)\n",
    "            d[(iteration, alpha)] = err\n",
    "    result = sorted(d.items(), key=lambda x: x[1])[0]\n",
    "    best_iter, best_alpha = result[0]\n",
    "    best_err = result[1]\n",
    "    return best_iter, best_alpha, best_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best num of iterations: 2000, best alpha: 0.1, log_loss: 0.3145853199959253\n"
     ]
    }
   ],
   "source": [
    "best_iter, best_alpha, best_err = optimize(logreg_eval_model_mod, np.transpose(X_st), y, np.arange(100, 2001, 100), np.array([0.0001, 0.001, 0.01, 0.1]))\n",
    "\n",
    "print(f'best num of iterations: {best_iter}, best alpha: {best_alpha}, log_loss: {best_err}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(W, X):\n",
    "    y_pred_proba = 1 / (1 + np.exp(-np.dot(W, X)))\n",
    "    return y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32651845 0.28501003 0.93478173 0.00799139 0.72661214 0.4955621\n",
      " 0.97234601 0.12687588 0.33737109 0.91817918]\n"
     ]
    }
   ],
   "source": [
    "W, err = logreg_eval_model_mod(X_st, y, iterations=best_iter, alpha=best_alpha)\n",
    "\n",
    "y_pred_proba = calc_pred_proba(W, X_st)\n",
    "\n",
    "print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(W, X, threshold=0.5):\n",
    "    y_pred_proba = calc_pred_proba(W, X)\n",
    "    y_pred = np.array([1 if proba >= threshold else 0 for proba in y_pred_proba], dtype = np.float64)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 1. 0. 1. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "W, err = logreg_eval_model_mod(X_st, y, iterations=best_iter, alpha=best_alpha)\n",
    "\n",
    "y_pred = calc_pred(W, X_st)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. *Реализуйте функции для подсчета Accuracy, матрицы ошибок, точности и полноты, а также F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_accuracy_score(y, y_pred):\n",
    "    return np.sum(y == y_pred) / len(y)\n",
    "\n",
    "def custom_confusion_matrix(y, y_pred):\n",
    "    tp, fp, fn, tn = 0, 0, 0, 0\n",
    "    for i, j in zip(y_pred, y):\n",
    "        if i == 1:\n",
    "            if j == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if j == 1:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    return np.array([[tp, fp], [fn, tn]])\n",
    "    \n",
    "def custom_precision_score(y, y_pred):\n",
    "    cm = custom_confusion_matrix(y, y_pred)\n",
    "    tp, fp = cm[0]\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def custom_recall_score(y, y_pred):\n",
    "    cm = custom_confusion_matrix(y, y_pred)\n",
    "    tp, fp = cm[0]\n",
    "    fn, tn = cm[1]\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def custom_f1_score(y, y_pred):\n",
    "    prc = custom_precision_score(y, y_pred)\n",
    "    rec = custom_recall_score(y, y_pred)\n",
    "    return 2 * prc * rec / (prc + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Metrics:\n",
      "    Accuracy: 0.9,\n",
      "    Confusion Matrix: [[5 1]\n",
      " [0 4]],\n",
      "    Precision: 0.8333333333333334,\n",
      "    Recall: 1.0,\n",
      "    F1: 0.9090909090909091\n",
      "\n",
      "Sklearn Metrics:\n",
      "    Accuracy: 0.9,\n",
      "    Confusion Matrix: [[4 1]\n",
      " [0 5]],\n",
      "    Precision: 0.8333333333333334,\n",
      "    Recall: 1.0,\n",
      "    F1 (sklearn): 0.9090909090909091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W, err = logreg_eval_model_mod(X_st, y, iterations=100, alpha=0.1)\n",
    "\n",
    "y_pred = calc_pred(W, X_st)\n",
    "\n",
    "custom_acc = custom_accuracy_score(y, y_pred)\n",
    "custom_cm = custom_confusion_matrix(y, y_pred)\n",
    "custom_prc = custom_precision_score(y, y_pred)\n",
    "custom_rec = custom_recall_score(y, y_pred)\n",
    "custom_f1 = custom_f1_score(y, y_pred)\n",
    "\n",
    "sklearn_acc = accuracy_score(y, y_pred)\n",
    "sklearn_cm = confusion_matrix(y, y_pred)\n",
    "sklearn_prc = precision_score(y, y_pred)\n",
    "sklearn_rec = recall_score(y, y_pred)\n",
    "sklearn_f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(f'Custom Metrics:\\n\\\n",
    "    Accuracy: {custom_acc},\\n\\\n",
    "    Confusion Matrix: {custom_cm},\\n\\\n",
    "    Precision: {custom_prc},\\n\\\n",
    "    Recall: {custom_rec},\\n\\\n",
    "    F1: {custom_f1}\\n')\n",
    "\n",
    "print(f'Sklearn Metrics:\\n\\\n",
    "    Accuracy: {sklearn_acc},\\n\\\n",
    "    Confusion Matrix: {sklearn_cm},\\n\\\n",
    "    Precision: {sklearn_prc},\\n\\\n",
    "    Recall: {sklearn_rec},\\n\\\n",
    "    F1 (sklearn): {sklearn_f1}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель могла переобучиться из-за слишком большого числа итераций алгоритма градиентный спуск, для предотвращения переобучения следует разбить данные на train/test (80/20 или 70/30) и использовать кросс-валидацию для оценки качества обобщающей способности модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проект: \n",
    "1. https://www.kaggle.com/c/regression-tutors-expected-math-exam-results регрессия\n",
    "1. https://www.kaggle.com/c/classification-choose-tutors классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBQTgdl2WjtW"
   },
   "source": [
    "## Дополнительные материалы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4eqL1suWjtW"
   },
   "source": [
    "1. [Функции потерь для классификации](https://en.wikipedia.org/wiki/Loss_functions_for_classification)\n",
    "\n",
    "2. Метод максимального правдоподобия: [Сложное описание](https://habr.com/ru/company/ods/blog/323890/#metod-maksimalnogo-pravdopodobiya) / [Простое описание](https://www.youtube.com/watch?v=2iRIqkm1mug)\n",
    "\n",
    "3. [Встроенные датасеты Sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets)\n",
    "\n",
    "4. Площаль под кривой [numpy.trapz](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.trapz.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v5wUbEYBWjtX"
   },
   "source": [
    "##  Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Логистическая регрессия - частный случай линейной классификации - предсказывает вероятность отнесения объекта к основному классу, что зачастую очень важно при интерпретации\n",
    "* Для \"отображения\" действительных предсказаний линейной модели в \"вероятностный\" интервал [0,1] применяют сигмоиду\n",
    "* Для обучения логистической регрессии используют логарифмическую функцию потерь (log-loss), полученную методом максимального правдоподобия (maximum likelihood estimation)\n",
    "* Оптимизируем log-loss классическим градиентным спуском, в котором берем градиент log-loss'а\n",
    "* Основными метриками качества классификатора являются Accuracy, Precision, Recall, ROC-AUC, PR-AUC, F-мера\n",
    "* Нужно быть внимательным при работе с этими метриками и хорошо понимать, как они работают и как между собой связаны, иначе выводы могут получиться неверными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Опеределения\n",
    "*Масштабирование данных*\n",
    "\n",
    "**Классификация** — задача, в которой имеется множество объектов, разделённых некоторым образом на классы.\n",
    "\n",
    "**Линейный классификатор** — алгоритм классификации, основанный на построении линейной разделяющей поверхности.\n",
    "\n",
    "**Отступ (для классификатора)** — эвристика, оценивающая то, насколько объект принадлежит классу, насколько эталонным представителем он является.\n",
    "____________\n",
    "_Логистическая регрессия_\n",
    "\n",
    "**Логистическая регрессия** — метод построения линейного классификатора, позволяющий оценивать апостериорные вероятности принадлежности объектов классам.\n",
    "\n",
    "**Риск** – отношение вероятности «положительный эффект» к вероятности «отрицательный эффект».\n",
    "\n",
    "**Логит** – натуральный логарифм отношения вероятности «положительный эффект» к вероятности «отрицательный эффект».\n",
    "____________\n",
    "_Метрики качества классификации_\n",
    "\n",
    "**Accuracy** – доля правильных ответов.\n",
    "\n",
    "$$accuracy(a,x) = \\frac{1}{l} \\sum^{l}_{i=1}[a(x_{i})=y_{i}].$$\n",
    "\n",
    "**Точность (precision)** – долю истинных срабатываний от общего количества срабатываний.\n",
    "\n",
    "$$precision(a, X) = \\frac{TP}{TP+FP}.$$\n",
    "\n",
    "**Полнота (recall)** – доля объектов, истинно относящихся к выбранному классу, которые алгоритм отнес к этому классу.\n",
    "\n",
    "$$recall(a, X) = \\frac{TP}{TP+FN},$$\n",
    "\n",
    "**F-мера** – среднее гармоническое между точностью и полнотой.\n",
    "\n",
    "$$F_{\\beta} = (1 + \\beta^{2}) \\frac{precision \\cdot recall}{\\beta^{2} \\cdot precision + recall}.$$\n",
    "\n",
    "**ROC-кривая** (receiver operating characteristic) — график, позволяющий оценить качество бинарной классификации, отображает соотношение между долей объектов от общего количества носителей признака, верно классифицированных как несущие признак (TPR), и долей объектов от общего количества объектов, не несущих признака, ошибочно классифицированных как несущие признак (FPR) при варьировании порога решающего правила.\n",
    "\n",
    "**PR-кривая** — график, позволяющий оценить качество бинарной классификации, отображает соотношение между Precision и Recall."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
